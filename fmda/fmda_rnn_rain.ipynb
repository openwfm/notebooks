{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7291842-a72d-4c4e-9312-6c0c31df18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both can change\n",
    "# Environment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from scipy.interpolate import LinearNDInterpolator, interpn\n",
    "from scipy.optimize import root\n",
    "from utils import hash2\n",
    "\n",
    "# Local modules for handling data and running moisture models\n",
    "import data_funcs as datf\n",
    "from data_funcs import format_raws, retrieve_raws, format_precip, fixnan\n",
    "from data_funcs import raws_data, synthetic_data, plot_data, check_data, mse_data, to_json, from_json\n",
    "import moisture_models as mod\n",
    "from moisture_rnn import create_RNN_2, staircase, create_rnn_data, train_rnn, rnn_predict\n",
    "\n",
    "meso_token=\"b40cb52cbdef43ef81329b84e8fd874f\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de795c3-3cad-454c-9f0b-94a9e937b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory for data read/write\n",
    "import os\n",
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8320fb68-771e-4441-8849-e5bdec432bd1",
   "metadata": {},
   "source": [
    "## Retrieve RAWS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e033c-5d16-44ec-9b58-4a55ff76d04d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raws_dat=raws_data(start='201806010800', hours=1200, h2=300, stid=\"BKCU1\",meso_token=meso_token)\n",
    "raws_dat=from_json('kf_orig.json')\n",
    "# hash2(raws_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1766b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_data(raws_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(raws_dat,hmax=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae5df3-b9a6-4102-83fa-99c21151ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_dat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c9d3d-8e11-461a-a4aa-276ae46a2cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('fm hash:', hash2(raws_dat['fm']))\n",
    "print('rain hash:', hash2(raws_dat['rain']))\n",
    "print('Ed hash:', hash2(raws_dat['Ed']))\n",
    "print('Ew hash:', hash2(raws_dat['Ew']))\n",
    "print('m hash:', hash2(raws_dat['m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b64034",
   "metadata": {},
   "source": [
    "## Interface\n",
    "Jonathon changes above  create each case as a dictionary, then dictionary of dictionaries, figure out how to store and load dictionaries as a file. json is possible but: cannot contain datetime objects\n",
    "look into pickle also compresses while json is plain text clone wrfxpy look how for idioms, pickle added jan/angel lager\n",
    "Jan will edit from here below. \n",
    "cases will be extracted from dictionary as global variables for now at least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1614583",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary raws_dat has all that is needed for the run \n",
    "# keeping the name raws_dat for now even if it may not be raws data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "synt_dat=synthetic_data()  # just testinh\n",
    "%matplotlib inline\n",
    "plot_data(synt_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c42a886-ecff-4379-8a12-db9a77d64045",
   "metadata": {},
   "source": [
    "## Fit Augmented KF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f34c54-0b60-428e-b7a0-b238126d82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_dat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8aa6b-a241-47e3-881f-6e75373f1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,Ec = mod.run_augmented_kf(raws_dat)  # extract from state\n",
    "raws_dat['m']=m\n",
    "raws_dat['Ec']=Ec\n",
    "plot_data(raws_dat,title2='augmented KF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98780d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(raws_dat,hmin=0,hmax=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5388f2-1c21-4b4e-860f-a7ea7c7e2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(raws_dat,hmin=900,hmax=1200,title2='augmented KF prediction detail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f0f20-b38f-4643-97cd-969914fca2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_data(raws_dat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a26c2-4a85-4c7e-b818-a1a2906dfb25",
   "metadata": {},
   "source": [
    "## Fit RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01143521-8222-4e69-9cde-7dc7c7c780e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5a394-c6f0-4af1-9890-37bf65ba0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# case_data = from_json('rnn_orig.json')\n",
    "with open('testing_dict.pickle', 'rb') as handle:\n",
    "    test_dict = pickle.load(handle)\n",
    "case_data = test_dict['case11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfc8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(case_data,title2=' from rnn_orig.json',hmin=0,hmax=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b93d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(case_data,title2='RNN prediction',hmin=300,hmax=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b34ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'm' in case_data:\n",
    "    mse_data(case_data)  # just check sdolution if there\n",
    "    del case_data['m']   # cleanup - remove old solution if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58615e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(123)\n",
    "rnn_dat = create_rnn_data(case_data,scale=False, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb655e2b-7288-4c69-ac4d-28079835270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check 1: equilibrium input data the same\n",
    "\n",
    "print(hash2(rnn_dat['Et']))\n",
    "print(hash2(rnn_dat['x_train']))\n",
    "print(hash2(rnn_dat['y_train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871821a9-bcd9-47db-9bd6-1933094ac137",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict = train_rnn(\n",
    "    rnn_dat,\n",
    "    rnn_dat['hours'],\n",
    "    activation=['linear','linear'],\n",
    "    hidden_units=6,\n",
    "    dense_units=1,\n",
    "    dense_layers=1,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3ec60-292d-4526-a793-7d466f4ce9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = rnn_predict(model_predict, rnn_dat, rnn_dat['hours'], verbose = verbose)\n",
    "case_data['m'] = m\n",
    "note = 'm replaced by a solution from fmda_rnn_rain'\n",
    "if 'note' in case_data:\n",
    "    case_data['note'] = case_data['note'] + '\\n' + note\n",
    "else:\n",
    "    case_data['note'] = note\n",
    "check_data(case_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc15fc-5d08-4df1-a4d5-4f0107171c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(case_data,title2='with trained RNN',hmin=0,hmax=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d06f6ee-2c05-4473-956c-ba490cf773d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_data(case_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1668f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(case_data,title2='RNN prediction',hmin=300,hmax=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e992b-31b6-4821-8a94-4de13c9e32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_predict.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aad4c9-f2c4-4897-9bab-c944ccd7ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a22cf6a-dfa8-45d5-9a4a-bba9f2fb386d",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f543ed01-a332-40e5-a668-92afaab7f9e9",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50864d30-c378-4e8b-9054-4cfafa4d2833",
   "metadata": {},
   "source": [
    "For a given RNN architecture, we train the model (<mark>from scratch each time for now</mark>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43459bc-afd0-489f-98ea-a6a1a2091fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rnn_test(d):\n",
    "    # Helper function to deploy RNN for multiple cases\n",
    "    # Given input dict, build rnn data, train model, and predcit\n",
    "    # Return: model output vector (ndarray)\n",
    "    \n",
    "    rnn_dat = create_rnn_data(d) # format data\n",
    "    model_predict = train_rnn(\n",
    "        rnn_dat,\n",
    "        rnn_dat['hours'],\n",
    "        activation=['linear','linear'],\n",
    "        hidden_units=6,\n",
    "        dense_units=1,\n",
    "        dense_layers=1,\n",
    "        verbose = False\n",
    "    )\n",
    "    m = rnn_predict(model_predict, rnn_dat, rnn_dat['hours'], verbose = verbose)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce888901-6656-435e-8e16-684f4e415b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_dict = {} # dictionary to save validation error for cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377cb2f-3e3c-4ad0-b826-4893e3805865",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "\n",
    "## Loop through dictionary and run RNN on cases\n",
    "for key in [*test_dict.keys()]:\n",
    "    print(key, ':', test_dict[key]['title'])\n",
    "    \n",
    "    dict1 = test_dict[key]\n",
    "    \n",
    "    \n",
    "    m = run_rnn_test(dict1)\n",
    "    \n",
    "    \n",
    "    dict1['m']=m\n",
    "    \n",
    "    errs = mse_data(dict1)\n",
    "    \n",
    "    print('-'*25)\n",
    "    \n",
    "    err_dict[key] = {\n",
    "        'title' : test_dict[key]['title'],\n",
    "        'train' : errs[0],\n",
    "        'test' : errs[1],\n",
    "        'm_hash' : int(hash2(m)),\n",
    "        'm' : m\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece869e-36b5-4853-b268-0c0b66b8ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print above output for visualization, save to text file\n",
    "\n",
    "print(cap.stdout)\n",
    "\n",
    "with open('errors_RNN1.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31152f8c-a2b5-40c2-a01d-6021b979e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Validation Outputs as pickle file with all data\n",
    "\n",
    "with open('errors_RNN1.pickle', 'wb') as handle:\n",
    "    pickle.dump(err_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa66d9ea-cd73-4a17-b4f6-db02acebd95d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
