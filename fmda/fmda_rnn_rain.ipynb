{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7291842-a72d-4c4e-9312-6c0c31df18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both can change\n",
    "# Environment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from scipy.interpolate import LinearNDInterpolator, interpn\n",
    "from scipy.optimize import root\n",
    "from utils import hash2\n",
    "\n",
    "# Local modules for handling data and running moisture models\n",
    "import data_funcs as datf\n",
    "from data_funcs import format_raws, retrieve_raws, format_precip, fixnan\n",
    "from data_funcs import raws_data, synthetic_data, plot_data, check_data, mse_data, to_json, from_json\n",
    "import moisture_models as mod\n",
    "from moisture_rnn import create_RNN_2, staircase, create_rnn_data, train_rnn, rnn_predict\n",
    "\n",
    "meso_token=\"b40cb52cbdef43ef81329b84e8fd874f\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de795c3-3cad-454c-9f0b-94a9e937b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory for data read/write\n",
    "import os\n",
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8320fb68-771e-4441-8849-e5bdec432bd1",
   "metadata": {},
   "source": [
    "## Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff87917-536b-4451-a472-90940d96a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# case_data = from_json('rnn_orig.json')\n",
    "with open('testing_dict.pickle', 'rb') as handle:\n",
    "    test_dict = pickle.load(handle)\n",
    "raws_dat = test_dict['case11']\n",
    "case_data=raws_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1766b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_data(raws_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(raws_dat,hmax=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae5df3-b9a6-4102-83fa-99c21151ecc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raws_dat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c9d3d-8e11-461a-a4aa-276ae46a2cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('fm hash:', hash2(raws_dat['fm']))\n",
    "print('rain hash:', hash2(raws_dat['rain']))\n",
    "print('Ed hash:', hash2(raws_dat['Ed']))\n",
    "print('Ew hash:', hash2(raws_dat['Ew']))\n",
    "if 'm' in raws_dat:\n",
    "    print('m hash:', hash2(raws_dat['m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b64034",
   "metadata": {},
   "source": [
    "## Interface\n",
    "Jonathon changes above  create each case as a dictionary, then dictionary of dictionaries, figure out how to store and load dictionaries as a file. json is possible but: cannot contain datetime objects\n",
    "look into pickle also compresses while json is plain text clone wrfxpy look how for idioms, pickle added jan/angel lager\n",
    "Jan will edit from here below. \n",
    "cases will be extracted from dictionary as global variables for now at least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1614583",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary raws_dat has all that is needed for the run \n",
    "# keeping the name raws_dat for now even if it may not be raws data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "synt_dat=synthetic_data()  # just testinh\n",
    "%matplotlib inline\n",
    "check_data(raws_dat)\n",
    "plot_data(synt_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b55ab-6142-4da5-b12c-350bac09d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours=raws_dat['hours']\n",
    "h2=raws_dat['h2'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c42a886-ecff-4379-8a12-db9a77d64045",
   "metadata": {},
   "source": [
    "## Fit Augmented KF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8aa6b-a241-47e3-881f-6e75373f1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,Ec = mod.run_augmented_kf(raws_dat)  # extract from state\n",
    "raws_dat['m']=m\n",
    "raws_dat['Ec']=Ec\n",
    "plot_data(raws_dat,title2='augmented KF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98780d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(raws_dat,hmin=0,hmax=h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5388f2-1c21-4b4e-860f-a7ea7c7e2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(raws_dat,hmin=h2,hmax=hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f0f20-b38f-4643-97cd-969914fca2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_data(raws_dat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a26c2-4a85-4c7e-b818-a1a2906dfb25",
   "metadata": {},
   "source": [
    "## Fit RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01143521-8222-4e69-9cde-7dc7c7c780e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfc8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(case_data,title2='from testing_dict.pickle',hmin=0,hmax=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b93d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(case_data,title2='from testing_dict.pickle',hmin=300,hmax=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b34ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'm' in case_data:\n",
    "    mse_data(case_data)  # just check sdolution if there\n",
    "    del case_data['m']   # cleanup - remove old solution if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58615e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(123)\n",
    "rnn_dat = create_rnn_data(case_data,scale=False, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb655e2b-7288-4c69-ac4d-28079835270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check 1: equilibrium input data the same\n",
    "\n",
    "print(hash2(rnn_dat['Et']))\n",
    "print(hash2(rnn_dat['x_train']))\n",
    "print(hash2(rnn_dat['y_train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871821a9-bcd9-47db-9bd6-1933094ac137",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict = train_rnn(\n",
    "    rnn_dat,\n",
    "    rnn_dat['hours'],\n",
    "    activation=['linear','linear'],\n",
    "    hidden_units=6,\n",
    "    dense_units=1,\n",
    "    dense_layers=1,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3ec60-292d-4526-a793-7d466f4ce9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = rnn_predict(model_predict, rnn_dat, rnn_dat['hours'], verbose = verbose)\n",
    "case_data['m'] = m\n",
    "note = 'm replaced by a solution from fmda_rnn_rain'\n",
    "if 'note' in case_data:\n",
    "    case_data['note'] = case_data['note'] + '\\n' + note\n",
    "else:\n",
    "    case_data['note'] = note\n",
    "check_data(case_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc15fc-5d08-4df1-a4d5-4f0107171c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(case_data,title2='with trained RNN',hmin=0,hmax=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d06f6ee-2c05-4473-956c-ba490cf773d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_data(case_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1668f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(case_data,title2='RNN prediction',hmin=300,hmax=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e992b-31b6-4821-8a94-4de13c9e32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hash2(case_data['m']))\n",
    "print(hash2(model_predict.get_weights()))\n",
    "print(model_predict.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a22cf6a-dfa8-45d5-9a4a-bba9f2fb386d",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62ad24d-7974-4f22-a797-3419e51e03f9",
   "metadata": {},
   "source": [
    "<mark>Start Here after Check 1<\\mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b68921-3745-4067-857c-9d4329d9c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import hash2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc82c0-2117-4b2b-b063-dbde46c856fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.set_random_seed(123)\n",
    "#tf.random.set_seed(123)\n",
    "reproducibility.set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09eb58-cd1f-4146-86d4-e60260d5f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import vprint\n",
    "\n",
    "hours = rnn_dat['hours']\n",
    "    \n",
    "samples = rnn_dat['samples']\n",
    "features = rnn_dat['features']\n",
    "timesteps = rnn_dat['timesteps']\n",
    "    \n",
    "model_fit=create_RNN_2(hidden_units=6, \n",
    "                        dense_units=1, \n",
    "                        batch_shape=(samples,timesteps,features),\n",
    "                        stateful=True,\n",
    "                        return_sequences=False,\n",
    "                        # initial_state=h0,\n",
    "                        activation=['linear','linear'],\n",
    "                        dense_layers=1)\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model_fit, to_file='model_plot.png', \n",
    "           show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030953b3-be17-40d7-b0b6-7e73e8b92869",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check 2: Untrained RNN initialized with same weights\n",
    "\n",
    "hash2(model_fit.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e09e0-7f47-4bc5-8cee-23752ac5bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Et = rnn_dat['Et']\n",
    "model_predict=create_RNN_2(hidden_units=6, dense_units=1,  \n",
    "                            input_shape=(hours,features),stateful = False,\n",
    "                            return_sequences=True,\n",
    "                            activation=['linear','linear'],dense_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a24ef-92ab-4657-87c6-aede6b7b89b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check 3: Second model initialization same weights\n",
    "\n",
    "hash2(model_predict.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d5c31-9bff-4df9-83f5-cf688f3291d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rnn_dat)\n",
    "x_train = rnn_dat['x_train']\n",
    "y_train = rnn_dat['y_train']\n",
    "type(x_train)\n",
    "\n",
    "# print dimensions and set initial state\n",
    "print('model_fit input shape',x_train.shape,'output shape',model_fit(x_train).shape)\n",
    "\n",
    "# fitting\n",
    "DeltaE = 0\n",
    "w_exact=  [np.array([[1.-np.exp(-0.1)]]), np.array([[np.exp(-0.1)]]), np.array([0.]),np.array([[1.0]]),np.array([-1.*DeltaE])]\n",
    "    \n",
    "w_initial=[np.array([[1.-np.exp(-0.1)]]), \n",
    "           np.array([[np.exp(-0.1)]]), \n",
    "           np.array([0.]),\n",
    "           np.array([[1.0]]),\n",
    "           np.array([-1.0])]\n",
    "r = 1e-2\n",
    "r = 0.\n",
    "print('randomization of initial weights ',r)\n",
    "w=model_fit.get_weights()\n",
    "for i in range(len(w)):\n",
    "    vprint('weight',i,'shape',w[i].shape,'ndim',w[i].ndim,'given',w_initial[i].shape)\n",
    "    for j in range(w[i].shape[0]):\n",
    "        if w[i].ndim==2:\n",
    "            for k in range(w[i].shape[1]):\n",
    "                w[i][j][k]=w_initial[i][0][0]/w[i].shape[0] + np.random.normal(0,1)*r\n",
    "        else:\n",
    "            w[i][j]=w_initial[i][0] + np.random.normal(0,1)*r\n",
    "model_fit.set_weights(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580caac4-ba9a-48b1-86a3-8e97357bf666",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check 4: weights and inputs the same after this step \n",
    "\n",
    "print(hash2(model_fit.get_weights()))\n",
    "print(hash2(x_train))\n",
    "print(hash2(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model_fit input shape',x_train.shape,'output shape',y_train.shape)\n",
    "print('x_train',x_train)\n",
    "print('y_train',y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2be797",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7857fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de62d29-2c91-48b5-a92f-da3deae470ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.fit(x_train, y_train, epochs=5000, verbose=2, batch_size=samples)\n",
    "w_fitted=model_fit.get_weights()\n",
    "for i in range(len(w)):\n",
    "    vprint('weight',i,' exact:',w_exact[i],':  initial:',w_initial[i],' fitted:',w_fitted[i])\n",
    "    \n",
    "model_predict.set_weights(w_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108b89d-0747-41bd-91fc-5716375d9d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check 5: Weights NOT the same after fitting\n",
    "\n",
    "hash2(model_fit.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fabcef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cece158-e7db-4d33-be09-03022e805b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0a46d-4fe3-4d8c-8411-f95ce2b465ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN weights repeated in odd way that looks like untrained\n",
    "\n",
    "model_fit.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b3b9c-7e7a-48a0-ac22-0e3ab4460e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "model_predict.set_weights(w_fitted)\n",
    "x_input=np.reshape(Et,(1, hours, 2))\n",
    "y_output = model_predict.predict(x_input)\n",
    "print('x_input.shape=',x_input.shape,'y_output.shape=',y_output.shape)\n",
    "# print(shift)\n",
    "m = np.reshape(y_output,hours)\n",
    "fitted_data = case_data.copy()\n",
    "fitted_data.update({'m':m,'title':\"First RNN forecast\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9a5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70653a4e-4363-439e-9d6f-5fdd88452702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
