{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b774b3-ef55-480a-b999-506676e49145",
   "metadata": {},
   "source": [
    "# Compare Batch Resetting Schedules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cc1dc4-3dcb-4325-9263-58101a3dc378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "import os.path as osp\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from moisture_rnn_pkl import pkl2train\n",
    "from moisture_rnn import RNNParams, RNNData, RNN \n",
    "from utils import hash2, read_yml, read_pkl, retrieve_url, print_dict_summary, print_first, str2time, logging_setup\n",
    "from moisture_rnn import RNN\n",
    "import reproducibility\n",
    "from data_funcs import rmse, to_json, combine_nested, build_train_dict, subset_by_features\n",
    "from moisture_models import run_augmented_kf\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import time\n",
    "import reproducibility\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db9b90-a931-4674-a447-5b8ffbcdc86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35319c1c-7849-4b8c-8262-f5aa6656e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"fmda_rocky_202403-05_f05.pkl\"\n",
    "retrieve_url(\n",
    "    url = f\"https://demo.openwfm.org/web/data/fmda/dicts/{filename}\", \n",
    "    dest_path = f\"../data/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152dacc1-33d2-465c-add3-3ce3fc5230b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_create=True\n",
    "train_write=True\n",
    "train_read=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabdbd9c-07d9-4bae-9851-cca79f321895",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=[filename]\n",
    "file_dir='../data'\n",
    "file_paths = [osp.join(file_dir,file_name) for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a1c2f-ba8d-40b8-b29c-daa38af97a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = RNNParams(read_yml(\"../params.yaml\", subkey='rnn'))\n",
    "params_data = read_yml(\"../params_data.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae0bdb-a209-429f-8116-c5e1dccafb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## params = RNNParams(read_yml(\"params.yaml\", subkey=\"rnn\"))\n",
    "params.update({'epochs': 200, \n",
    "               'learning_rate': 0.001,\n",
    "               'activation': ['tanh', 'tanh'], # Activation for RNN Layers, Dense layers respectively.\n",
    "               'rnn_layers': 2, 'recurrent_units': 30, \n",
    "               'dense_layers': 2, 'dense_units': 30,\n",
    "               'early_stopping_patience': 30, # how many epochs of no validation accuracy gain to wait before stopping\n",
    "               'batch_schedule_type': 'exp', # Hidden state batch reset schedule\n",
    "               'bmin': 20, # Lower bound of hidden state batch reset, \n",
    "               'bmax': params_data['hours'], # Upper bound of hidden state batch reset, using max hours\n",
    "               'features_list': ['Ed', 'Ew', 'rain', 'elev', 'lon', 'lat', 'solar', 'wind'],\n",
    "               'timesteps': 12,\n",
    "               'batch_size': 50,\n",
    "               'time_fracs': [.9, .05, .05],\n",
    "               'space_fracs': [.8, .1, .1]\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a71c425-1fe4-43ad-9300-01885e9f4873",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_data.update({\n",
    "    'hours': 2208,\n",
    "    'max_intp_time': 12,\n",
    "    'zero_lag_threshold': 12\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96cfe85-3279-49e0-b1ea-a0243a985e49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if train_create:\n",
    "    # Not doing spatial combine yet since we want to filter locations to those with complete RAWS sensors\n",
    "    train = build_train_dict(file_paths, atm_source=\"HRRR\", \n",
    "                             params_data = params_data, \n",
    "                             forecast_step = 0, drop_na = True,\n",
    "                             spatial=False, verbose=True)\n",
    "    train1 = build_train_dict(file_paths, atm_source=\"HRRR\", \n",
    "                             params_data = params_data, \n",
    "                             forecast_step = 1, drop_na = True,\n",
    "                             spatial=False, verbose=True)\n",
    "    train2 = build_train_dict(file_paths, atm_source=\"HRRR\", \n",
    "                             params_data = params_data, \n",
    "                             forecast_step = 2, drop_na = True,\n",
    "                             spatial=False, verbose=True)\n",
    "    train3 = build_train_dict(file_paths, atm_source=\"HRRR\", \n",
    "                             params_data = params_data, \n",
    "                             forecast_step = 3, drop_na = True,\n",
    "                             spatial=False, verbose=True)\n",
    "    trainr = build_train_dict(file_paths, atm_source=\"RAWS\", \n",
    "                             params_data = params_data, \n",
    "                             spatial=False, verbose=True,\n",
    "                             features_subset = params['features_list']\n",
    "                             )\n",
    "\n",
    "    trainr = subset_by_features(trainr, input_features = params['features_list'])\n",
    "\n",
    "    # Subset HRRR dicts to those with complete RAWS sensors\n",
    "    train = {k: train[k] for k in train if k in trainr}\n",
    "    train1 = {k: train1[k] for k in train1 if k in trainr}\n",
    "    train2 = {k: train2[k] for k in train2 if k in trainr}\n",
    "    train3 = {k: train3[k] for k in train3 if k in trainr}\n",
    "\n",
    "    trainr = combine_nested(trainr)\n",
    "    if train_write:\n",
    "        with open(\"../data/train_raws.pkl\", 'wb') as file:\n",
    "            pickle.dump(trainr, file)\n",
    "        with open(\"../data/train_0hr.pkl\", 'wb') as file:\n",
    "            pickle.dump(combine_nested(train), file)\n",
    "        with open(\"../data/train_1hr.pkl\", 'wb') as file:\n",
    "            pickle.dump(combine_nested(train1), file)\n",
    "        with open(\"../data/train_2hr.pkl\", 'wb') as file:\n",
    "            pickle.dump(combine_nested(train2), file)\n",
    "        with open(\"../data/train_3hr.pkl\", 'wb') as file:\n",
    "            pickle.dump(combine_nested(train3), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7477e21-b629-42ab-99e3-bf4fa3926b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "if train_read:\n",
    "    trainr = read_pkl(\"../data/train_raws.pkl\")\n",
    "    train = read_pkl(\"../data/train_0hr.pkl\")\n",
    "    train1 = read_pkl(\"../data/train_1hr.pkl\")\n",
    "    train2 = read_pkl(\"../data/train_2hr.pkl\")\n",
    "    train3 = read_pkl(\"../data/train_3hr.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6751dcc-ba4c-47d5-90d2-60f4a61e96fa",
   "metadata": {},
   "source": [
    "## Handle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83820dbd-4fb9-48d3-8dba-98fb10a7ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_data_wrap(dict0, params):\n",
    "    rnn_dat = RNNData(\n",
    "        dict0, # input dictionary\n",
    "        scaler=\"standard\",  # data scaling type\n",
    "        features_list = params['features_list'] # features for predicting outcome\n",
    "    )\n",
    "    \n",
    "    \n",
    "    rnn_dat.train_test_split(   \n",
    "        time_fracs = params['time_fracs'], # Percent of total time steps used for train/val/test\n",
    "        space_fracs = params['space_fracs'] # Percent of total timeseries used for train/val/test\n",
    "    )\n",
    "    rnn_dat.scale_data()\n",
    "    \n",
    "    rnn_dat.batch_reshape(\n",
    "        timesteps = params['timesteps'], # Timesteps aka sequence length for RNN input data. \n",
    "        batch_size = params['batch_size'], # Number of samples of length timesteps for a single round of grad. descent\n",
    "        start_times = np.zeros(len(rnn_dat.loc['train_locs']))\n",
    "    )    \n",
    "    \n",
    "    return rnn_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e1061-e60e-45f3-9e1a-99b088cc5a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fstep_m = [] # model outputs\n",
    "fstep_errs = [] # errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a93a6-335a-493f-a6b2-e4b6f5d5c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fsteps = [train, train1, train2, train3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34ff1f-6d4c-46a3-82e2-b32a4c63a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_i in train_fsteps:\n",
    "    print(\"~\"*100)\n",
    "    print(f\"Running Model for Forecast Step: {train_i['forecast_step'][0]}\")\n",
    "    reproducibility.set_seed()\n",
    "    data = rnn_data_wrap(train_i, params)\n",
    "    params.update({\n",
    "        'loc_batch_reset': data.n_seqs # Used to reset hidden state when location changes for a given batch\n",
    "    })\n",
    "    \n",
    "    rnn = RNN(params)\n",
    "    m, errs = rnn.run_model(data)\n",
    "\n",
    "    print(f\"Test RMSE: {errs.mean()}\")\n",
    "    \n",
    "    fstep_m.append(m)\n",
    "    fstep_errs.append(errs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c55c254-6470-43fb-ad16-85eb917a555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"~\"*100)\n",
    "print(f\"Running Model for RAWS atmospheric data\")\n",
    "reproducibility.set_seed()\n",
    "data = rnn_data_wrap(trainr, params)\n",
    "params.update({\n",
    "    'loc_batch_reset': data.n_seqs # Used to reset hidden state when location changes for a given batch\n",
    "})\n",
    "\n",
    "rnn = RNN(params)\n",
    "m, errs = rnn.run_model(data)\n",
    "\n",
    "fstep_m.append(m)\n",
    "fstep_errs.append(errs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11afb9ae-772b-4fe4-9b67-db7b18816304",
   "metadata": {},
   "source": [
    "## Compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e3f85-7c1e-487d-b42d-12bfaffc2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean(array) for array in fstep_errs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255e9ab-f518-4543-8f30-9de33387b912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fa23ef5-0e37-40b7-9f77-d62a15437819",
   "metadata": {},
   "source": [
    "## Analyze Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889b297-f2e9-4eb6-b02b-5d5fb32b7624",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.model_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd1f919-0654-44bf-86b9-9196b843c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.model_train.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25448e8-91d5-4f0b-87a8-d1c93f710867",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['n_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8535c86c-b62c-4ce3-a732-dddb4c44c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['rnn_units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c766951-cb59-4961-bd99-1cf21bc595f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['features_list'].index('rain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26727ff-5895-40ae-963d-e57403c02282",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.model_train.get_weights()[0][2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154471e9-9586-4d3e-aadf-509ad403eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights = np.mean(np.abs(rnn.model_train.get_weights()[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0101df2-8d89-4e59-b68a-4ddc8e0d6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da0c86-5792-4b9c-b09f-2f4582453864",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feat in enumerate(params['features_list']):\n",
    "    print(f\"Feature {feat} mean input weight: {feature_weights[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eea9ff-e4ad-49a1-a3e4-0603924b0ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9585f2a-87fc-49bc-9851-8c9b2efb8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainr['features_list'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d1e4ee-be80-4fc1-85fd-26af69371965",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['features_list'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab71ca-5ed6-48e1-893c-2f80ef586fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train3['features_list'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110755a-d469-47f1-ac47-8dcf83b6ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(np.vstack(trainr['X'])[:, -1], np.vstack(train['X'])[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f964007-2d6e-4706-bc44-843586eeb903",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(np.vstack(trainr['X'])[:, -1]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11007004-cd36-46a6-8b7b-bff0846368b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(\n",
    "    np.vstack([array[1:] for array in trainr[\"X\"]])[:,-1], \n",
    "    np.vstack(train1['X'])[:, -1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ebd98-40da-4682-adbe-0f5f0b452269",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(\n",
    "    np.vstack([array[2:] for array in trainr[\"X\"]])[:,-1], \n",
    "    np.vstack(train2['X'])[:, -1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18691bc4-8213-46d7-8a15-a55562fdf2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(\n",
    "    np.vstack([array[3:] for array in trainr[\"X\"]])[:,-1], \n",
    "    np.vstack(train3['X'])[:, -1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256fae9-5d32-4793-8f4b-01252223f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainr['features_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9283fa92-e23f-4124-8baa-55a97b2a6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train3['features_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c442885-93ae-42e3-a243-f048507c5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(\n",
    "    np.vstack([array[3:] for array in trainr[\"X\"]])[:,-3], \n",
    "    np.vstack(train3['X'])[:, -3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f07f0-dff5-497d-8ee5-d38927ff7d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f0e34-6b57-4159-992d-fabba895b629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc3a6f-ad63-47c8-982d-92a4240802dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
