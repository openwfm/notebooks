{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244c2fb0-4339-476c-a2db-a641e124e25a",
   "metadata": {},
   "source": [
    "# v2 exploration trying to make it work better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc7920-e380-4b81-bac0-cd6840450e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# Local modules\n",
    "sys.path.append('..')\n",
    "import reproducibility\n",
    "import pandas as pd\n",
    "from utils import print_dict_summary\n",
    "from data_funcs import load_and_fix_data, rmse\n",
    "from moisture_rnn import RNNParams, RNN, RNN_LSTM, create_rnn_data2\n",
    "from moisture_rnn_pkl import pkl2train\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from utils import hash2\n",
    "import copy\n",
    "import logging\n",
    "import pickle\n",
    "from utils import logging_setup, read_yml\n",
    "import yaml\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e8839-bf0e-4995-b966-c09e4df001ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2298a1a1-b72c-4c7e-bcb6-2cdefe96fe3e",
   "metadata": {},
   "source": [
    "## Test Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e05fe-8353-41c3-be42-4051d2eb589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file='train.pkl'\n",
    "with open(train_file,'rb') as file:\n",
    "    train=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b662edb-7a79-4532-b0d7-2492b1ad917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_yml(\"params.yaml\", subkey=\"rnn\")\n",
    "params = RNNParams(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff8052-4a40-4c7a-bb29-aabfc4d1ae92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c10ca8-ce5c-4fe8-86be-2d34174914c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import moisture_rnn\n",
    "importlib.reload(moisture_rnn)\n",
    "from moisture_rnn import create_rnn_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186a280-893f-4571-88a0-138730d0216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat = create_rnn_data2(train['PIVC1_202401'], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935ca01-4e23-4a3f-98de-44063487490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b1365-8310-4877-a9f3-477533420e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22ca3a-8546-4b3c-b9cc-1664f358f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scalers = {\n",
    "    'minmax': MinMaxScaler(),\n",
    "    'standard': StandardScaler() \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230b4a7-9eb4-42a0-93c5-057b4eaa1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_items_exist(source_list, target_list):\n",
    "    return all(item in target_list for item in source_list)\n",
    "\n",
    "class RNNData(dict):\n",
    "    required_keys = {\"loc\", \"time\", \"X\", \"y\", \"features_list\"}  \n",
    "    def __init__(self, input_dict, features_list=None, scaler=None):\n",
    "        # Copy to avoid \n",
    "        input_data = input_dict.copy()\n",
    "        super().__init__(input_data)\n",
    "        self.scaler = None\n",
    "        if scaler is not None:\n",
    "            self.set_scaler(scaler)\n",
    "        self['hours'] = len(self['y'])\n",
    "        self['all_features_list'] = self.pop('features_list')\n",
    "        if features_list is None:\n",
    "            print(\"Using all input features.\")\n",
    "            self.features_list = self.all_features_list\n",
    "        else:\n",
    "            self.features_list = features_list\n",
    "        self.run_checks()\n",
    "        self.__dict__.update(self)\n",
    "    def run_checks(self, verbose=True):\n",
    "        missing_keys = self.required_keys - self.keys()\n",
    "        if missing_keys:\n",
    "            raise KeyError(f\"Missing required keys: {missing_keys}\")\n",
    "        # Check y 1-d\n",
    "        y_shape = np.shape(self.y)\n",
    "        if not (len(y_shape) == 1 or (len(y_shape) == 2 and y_shape[1] == 1)):\n",
    "            raise ValueError(f\"'y' must be one-dimensional, with shape (N,) or (N, 1). Current shape is {y_shape}.\")\n",
    "        \n",
    "        # Check if 'hours' is provided and matches len(y)\n",
    "        if 'hours' in self:\n",
    "            if self.hours != len(self.y):\n",
    "                raise ValueError(f\"Provided 'hours' value {self.hours} does not match the length of 'y', which is {len(self.y)}.\")\n",
    "        # Check desired subset of features is in all input features\n",
    "        if not all_items_exist(self.features_list, self.all_features_list):\n",
    "            raise ValueError(f\"Provided 'features_list' {self.features_list} has elements not in input features.\")\n",
    "    def set_scaler(self, scaler):\n",
    "        recognized_scalers = ['minmax', 'standard']\n",
    "        if scaler in recognized_scalers:\n",
    "            self.scaler = scalers[scaler]\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized scaler '{scaler}'. Recognized scalers are: {recognized_scalers}.\")\n",
    "    def train_test_split(self, train_frac, val_frac=0.0, subset_features=True, features_list=None, split_time=True, split_space=False, verbose=True):\n",
    "        # Extract data to desired features\n",
    "        X = self.X.copy()\n",
    "        y = self.y.copy()\n",
    "        if subset_features:\n",
    "            if verbose and d.features_list != d.all_features_list:\n",
    "                print(f\"Subsetting input data to features_list: {self.features_list}\")\n",
    "            # Indices to subset all features with based on params features\n",
    "            indices = []\n",
    "            for item in self.features_list:\n",
    "                if item in self.all_features_list:\n",
    "                    indices.append(self.all_features_list.index(item))\n",
    "                else:\n",
    "                    print(f\"Warning: feature name '{item}' not found in list of all features from input data\")\n",
    "            X = X[:, indices]\n",
    "        # Setup train/test in time\n",
    "        train_ind = int(np.floor(self.hours * train_frac)); self.train_ind = train_ind\n",
    "        test_ind= int(train_ind + round(self.hours * val_frac)); self.test_ind = test_ind\n",
    "\n",
    "        # Check for any potential issues with indices\n",
    "        if test_ind > self.hours:\n",
    "            print(\"Setting test index to {self.hours}\")\n",
    "            test_ind = self.hours\n",
    "        if train_ind >= test_ind:\n",
    "            raise ValueError(\"Train index must be less than test index.\")        \n",
    "        \n",
    "        # Training data from 0 to train_ind\n",
    "        self.X_train = X[:train_ind]\n",
    "        self.y_train = y[:train_ind].reshape(-1,1) # assumes y 1-d, change this if vector output\n",
    "        # Validation data from train_ind to test_ind\n",
    "        if val_frac >0:\n",
    "            self.X_val = X[train_ind:test_ind]\n",
    "            self.y_val = y[train_ind:test_ind].reshape(-1,1) # assumes y 1-d, change this if vector output\n",
    "        # Test data from test_ind to end\n",
    "        self.X_test = X[test_ind:]\n",
    "        self.y_test = y[test_ind:].reshape(-1,1) # assumes y 1-d, change this if vector output\n",
    "\n",
    "        # Print statements if verbose\n",
    "        if verbose:\n",
    "            print(f\"Train index: 0 to {train_ind}\")\n",
    "            print(f\"Validation index: {train_ind} to {test_ind}\")\n",
    "            print(f\"Test index: {test_ind} to {self.hours}\")\n",
    "            print(f\"X_train shape: {self.X_train.shape}, y_train shape: {self.y_train.shape}\")\n",
    "            print(f\"X_val shape: {self.X_val.shape}, y_val shape: {self.y_val.shape}\")\n",
    "            print(f\"X_test shape: {self.X_test.shape}, y_test shape: {self.y_test.shape}\")\n",
    "    def scale_data(self, verbose=True):\n",
    "        if self.scaler is None:\n",
    "            raise ValueError(\"Scaler is not set. Use 'set_scaler' method to set a scaler before scaling data.\")\n",
    "        if not hasattr(self, \"X_train\"):\n",
    "            raise AttributeError(\"No X_train within object. Run train_test_split first. This is to avoid fitting the scaler with prediction data.\")\n",
    "        if verbose:\n",
    "            print(f\"Scaling data with scaler {self.scaler}, fitting on X_train\")\n",
    "        # Fit the scaler on the training data\n",
    "        self.scaler.fit(self.X_train)      \n",
    "        # Transform the data using the fitted scaler\n",
    "        self.X_train = self.scaler.transform(self.X_train)\n",
    "        if hasattr(self, 'X_val'):\n",
    "            self.X_val = self.scaler.transform(self.X_val)\n",
    "        self.X_test = self.scaler.transform(self.X_test)\n",
    "    def __getattr__(self, key):\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError:\n",
    "            raise AttributeError(f\"'rnn_data' object has no attribute '{key}'\")\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        super().__setitem__(key, value)  # Update the dictionary\n",
    "        if key in self.required_keys:\n",
    "            super().__setattr__(key, value)  # Ensure the attribute is updated as well\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self[key] = value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9125ab9-4f23-43e5-a3f2-c58957ac95dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8407b1a-24a9-4033-9bfe-31f7efced9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fcabf4-3e92-489f-95ed-2b727928289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = RNNData(train['PIVC1_202401'], features_list=['Ed', 'Ew', 'rain'], scaler='minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36b13ee-8a66-44ab-b5a2-1ec98a7adf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(d.scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e4a1d1-a364-40f0-8213-1bede4250f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.scale_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659bb7f-b961-4721-8512-c609014daa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc27903-76cc-4fb1-a57a-2aa3e60fe93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.train_test_split(train_frac = .5, val_frac = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd6c36-cf9b-43f0-9f08-62dbe1a6ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.scale_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc2cf7-eab1-4a85-8632-4d306aead358",
   "metadata": {},
   "source": [
    "## Test RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e9f3de-d0ea-40b5-8496-311b735492bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d53b27-d699-4ba9-a1bc-7e9c12835be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# case = [*train.keys()][1]\n",
    "case = \"FCHC1_202401\"\n",
    "print(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3c25a-cf08-4a6d-be2e-21afb861c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.update({'val_frac': .2, 'scale': True, 'scaler': 'standard', 'epochs': 200})\n",
    "# params.update({'features_list': ['wind', 'Ed', 'Ew', 'solar', 'rain']})\n",
    "params.update({'rnn_layers': 3})\n",
    "rnn_dat = create_rnn_data2(train[case], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1147c-e882-4b67-9e77-36a3b4b8bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed()\n",
    "rnn = RNN(params)\n",
    "m, errs = rnn.run_model(rnn_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888dd72a-4eef-414b-ac33-f6f4bfbefe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f40cdfd-b33a-43c1-8bc4-44a0ea6817ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib \n",
    "import moisture_rnn\n",
    "importlib.reload(moisture_rnn)\n",
    "from moisture_rnn import RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf0ba2e-f944-4c86-a20e-a59e023897cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_yml(\"params.yaml\", subkey=\"rnn\")\n",
    "params = RNNParams(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd51b0-9342-4b90-a250-0ac2c75d3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed()\n",
    "rnn = RNN(params)\n",
    "m, errs = rnn.run_model(rnn_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7d34c-dfae-4370-a398-a287790eff53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2360aef-e9c4-4a71-922d-336e53b82537",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4e441-9bf1-4d57-bb37-091553e23212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib \n",
    "import moisture_rnn\n",
    "importlib.reload(moisture_rnn)\n",
    "from moisture_rnn import RNN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59480f19-3567-4b24-b6ff-d9292dc8c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"params.yaml\") as file:\n",
    "    params = yaml.safe_load(file)[\"lstm\"]\n",
    "    \n",
    "rnn_dat2 = create_rnn_data2(train[case],params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adff592-7aa4-4e59-a229-cad4a133297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.update({'epochs': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20539f0-eed2-44de-9269-ae8696c8e7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfbcbb5-b631-4594-9ae5-618c4fe68e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed()\n",
    "rnn = RNN(params)\n",
    "m, errs = rnn.run_model(rnn_dat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a9700-f479-4c11-8655-ca7b45222402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de46c481-74a7-46cc-8334-678ad8230cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(moisture_rnn)\n",
    "from moisture_rnn import RNN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6a699a-68e8-49ef-95f2-409137502fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"params.yaml\") as file:\n",
    "    params = yaml.safe_load(file)[\"lstm\"]\n",
    "\n",
    "rnn_dat2 = create_rnn_data2(train[case],params)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c0d5d-f3f6-4a61-83b0-b21dfc5d01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.update({\n",
    "    'learning_rate': 0.000001,\n",
    "    'epochs': 10,\n",
    "    'clipvalue':1.0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9d612e-8cd2-40ca-a789-91c99c3d6ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed()\n",
    "lstm = RNN_LSTM(params)\n",
    "m, errs = lstm.run_model(rnn_dat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec95e7d4-6d57-441b-b673-f10625ee5dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c8d8d-ea50-44ea-8c0c-414e07cd01ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03063e3c-e8f4-451d-b0cf-25bd965cd9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a24c6-9a67-45aa-bc5c-8818aa0ca049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
