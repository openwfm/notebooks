{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244c2fb0-4339-476c-a2db-a641e124e25a",
   "metadata": {},
   "source": [
    "# v2.1 exploration trying to make it work better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc7920-e380-4b81-bac0-cd6840450e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# Local modules\n",
    "sys.path.append('..')\n",
    "import reproducibility\n",
    "import pandas as pd\n",
    "from utils import print_dict_summary\n",
    "from data_funcs import rmse, build_train_dict, combine_nested, subset_by_features\n",
    "from moisture_rnn import RNNParams, RNNData, RNN, RNN_LSTM, rnn_data_wrap\n",
    "from moisture_rnn_pkl import pkl2train\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from utils import hash2\n",
    "import copy\n",
    "import logging\n",
    "import pickle\n",
    "from utils import logging_setup, read_yml, read_pkl, hash_ndarray, hash_weights, str2time\n",
    "import yaml\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e8839-bf0e-4995-b966-c09e4df001ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae67b50-f916-45a7-bcc7-61995ba39449",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efed1fa-9cda-4934-8a6c-edcf179c8755",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['data/fmda_rocky_202403-05_f05.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd3746-1861-4afa-ab7e-ac449fbed322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params used for data filtering\n",
    "params_data = read_yml(\"params_data.yaml\") \n",
    "params_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a46674-8377-47f8-9c3a-e6b07f9505cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_yml(\"params.yaml\", subkey='rnn') \n",
    "params = RNNParams(params)\n",
    "params.update({'epochs': 200, \n",
    "               'learning_rate': 0.001,\n",
    "               'activation': ['tanh', 'tanh'], # Activation for RNN Layers, Dense layers respectively.\n",
    "               'recurrent_layers': 2, 'recurrent_units': 30, \n",
    "               'dense_layers': 2, 'dense_units': 30,\n",
    "               'early_stopping_patience': 30, # how many epochs of no validation accuracy gain to wait before stopping\n",
    "               'batch_schedule_type': 'exp', # Hidden state batch reset schedule\n",
    "               'bmin': 20, # Lower bound of hidden state batch reset, \n",
    "               'bmax': params_data['hours'], # Upper bound of hidden state batch reset, using max hours\n",
    "               'features_list': ['Ed', 'Ew', 'rain', 'elev', 'lon', 'lat', 'solar', 'wind'],\n",
    "               'timesteps': 12\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45cb8ef-41fc-4bf7-b506-dad5fd24abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = read_pkl(file_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c960d69-4f8a-4abb-a5d9-ed6cf98f899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import data_funcs\n",
    "importlib.reload(data_funcs)\n",
    "from data_funcs import build_train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369cd913-85cb-4855-a80c-817d84637852",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_data.update({'hours': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc2ce8-45b4-4caa-81d9-646271ff2e97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train3 = build_train_dict(file_paths, params_data, spatial=False, forecast_step=3, drop_na=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4548ae-caa4-4bc4-9122-9f24e7e59ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb6f24-4435-47b3-90c6-6176582b0d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6322f0bc-107d-40a5-96dc-804495085a99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Test Other ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12992b9a-407f-4131-ac61-e1dc338386bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_yml(\"params.yaml\", subkey='xgb')\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214fdf8-bb76-4912-8f8c-5d0c8c1230c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = read_pkl(\"data/train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b7805-15f6-4c09-a05b-7aed7d253f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [*dat.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375055d8-c070-4639-9561-e47d3f21f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat = RNNData(dat[cases[10]], params['scaler'], params['features_list'])\n",
    "rnn_dat.train_test_split(\n",
    "    time_fracs = [.8, .1, .1]\n",
    ")\n",
    "rnn_dat.scale_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f8dc8-5cf8-4190-b4ff-e640f61bd78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moisture_models import XGB, RF, LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aeb47f-261e-4e29-9eeb-67215e5628f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = XGB(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9a20d-1caf-45aa-a9c4-aef21b65d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a07b25-c586-4fc4-a3d5-c857354e7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.fit(rnn_dat.X_train, rnn_dat.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f88819-0a7a-4420-abb9-56a47015a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mod.predict(rnn_dat.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7cdf14-74d6-45e4-bc1b-7d4d47dd41ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(preds, rnn_dat.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d478c7-8c01-448e-9a00-dd0e1ee8e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rnn_dat.y_test)\n",
    "plt.plot(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5441014-c39a-4414-a779-95b81e1ed6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_yml(\"params.yaml\", subkey='rf')\n",
    "rnn_dat = RNNData(dat[cases[10]], features_list = ['Ed', 'Ew', 'solar', 'wind', 'rain'])\n",
    "rnn_dat.train_test_split(\n",
    "    time_fracs = [.8, .1, .1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe711a-20cb-4bd3-a4bc-4995a843a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import moisture_models\n",
    "importlib.reload(moisture_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee45f7d6-f57f-4ff6-995a-527565565f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe76e5-0212-4bd1-a058-535935a08780",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2 = RF(params)\n",
    "mod2.fit(rnn_dat.X_train, rnn_dat.y_train.flatten())\n",
    "preds2 = mod2.predict(rnn_dat.X_test)\n",
    "print(rmse(preds2, rnn_dat.y_test.flatten()))\n",
    "plt.plot(rnn_dat.y_test)\n",
    "plt.plot(preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab4244-996c-49af-bf4a-8b0c47b0b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moisture_models import RF\n",
    "mod2 = RF(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c33fd-db35-4c77-9eee-fdb39a934959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5598bfe-2d87-4d23-869e-aff127782462",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_yml(\"params.yaml\", subkey='lm')\n",
    "rnn_dat = RNNData(dat[cases[10]], features_list = ['Ed', 'Ew', 'solar', 'wind', 'rain'])\n",
    "rnn_dat.train_test_split(\n",
    "    time_fracs = [.8, .1, .1]\n",
    ")\n",
    "mod = LM(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828c15c-4078-4967-abff-c1fd15d4696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.fit(rnn_dat.X_train, rnn_dat.y_train)\n",
    "preds = mod.predict(rnn_dat.X_test)\n",
    "print(rmse(preds2, rnn_dat.y_test.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496a32a-8269-4d6b-953e-7f33fe626789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce8bf3-6efb-4dc7-b895-def92f6ce6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6e089d9-e466-45bb-80f2-15c563ae21ad",
   "metadata": {},
   "source": [
    "## Class RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c4083-3052-4df1-9cfb-535112ab5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_test = {\n",
    "    'n_features': 3,\n",
    "    'timesteps': 12,\n",
    "    'batch_size': 32,\n",
    "    'hidden_layers': ['LSTM', 'attention', 'dense'],\n",
    "    'hidden_units': [32, None, 32],\n",
    "    'hidden_activation': ['tanh', None, 'relu'],\n",
    "    'dropout': 0.2,\n",
    "    'recurrent_dropout': 0.2,\n",
    "    'output_layer': 'dense',\n",
    "    'output_activation': 'linear',\n",
    "    'output_dimension': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e78e33f-96e9-4dcc-adf9-e11716280f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c763c2f-22ed-45aa-bcfe-06cec8be7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_from_params(params):\n",
    "    # Define the input layer with the specified batch size, timesteps, and features\n",
    "    inputs = tf.keras.Input(batch_shape=(params['batch_size'], params['timesteps'], params['n_features']))\n",
    "    x = inputs\n",
    "\n",
    "    # Loop over each layer specified in 'hidden_layers'\n",
    "    for i, layer_type in enumerate(params['hidden_layers']):\n",
    "        units = params['hidden_units'][i]\n",
    "        activation = params['hidden_activation'][i]\n",
    "\n",
    "        if layer_type == 'dense':\n",
    "            x = layers.Dense(units=units, activation=activation)(x)\n",
    "\n",
    "        elif layer_type == 'dropout':\n",
    "            x = layers.Dropout(params['dropout'])(x)\n",
    "        \n",
    "        elif layer_type == 'rnn':\n",
    "            x = layers.SimpleRNN(units=units, activation=activation, dropout=params['dropout'], recurrent_dropout=params['recurrent_dropout'],\n",
    "                                 return_sequences=True, stateful=True)(x)\n",
    "        \n",
    "        elif layer_type == 'lstm':\n",
    "            x = layers.LSTM(units=units, activation=activation, dropout=params['dropout'], recurrent_dropout=params['recurrent_dropout'],\n",
    "                            return_sequences=True, stateful=True)(x)    \n",
    "        \n",
    "        elif layer_type == 'attention':\n",
    "            # Self-attention mechanism\n",
    "            x = layers.Attention()([x, x])\n",
    "\n",
    "    # Add the output layer\n",
    "    if params['output_layer'] == 'dense':\n",
    "        outputs = layers.Dense(units=params['output_dimension'], activation=params['output_activation'])(x)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported output layer type: {}\".format(params['output_layer']))\n",
    "    \n",
    "    # Create the model\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a784b-ab12-4ccb-8c79-27e8961f14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42227627-60ab-44c6-a1fc-d8e557a33150",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_from_params(params_test)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb65bcb-b072-43e2-96af-aa91a17c4c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Example optimizer\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9240e98-2bae-4241-9b0c-2e58cebe23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(rnn_dat.X_train, rnn_dat.y_train, validation_data = (rnn_dat.X_val, rnn_dat.y_val), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e362d68-dad5-4497-b698-311ff5755875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prediction_model_from_params(params):\n",
    "    # Define the input layer with flexible batch size and sequence length\n",
    "    inputs = tf.keras.Input(shape=(None, params['n_features']))\n",
    "    x = inputs\n",
    "\n",
    "    # Loop over each layer specified in 'hidden_layers'\n",
    "    for i, layer_type in enumerate(params['hidden_layers']):\n",
    "        units = params['hidden_units'][i]\n",
    "        activation = params['hidden_activation'][i]\n",
    "\n",
    "        if layer_type == 'dense':\n",
    "            x = layers.Dense(units=units, activation=activation)(x)\n",
    "\n",
    "        elif layer_type == 'rnn':\n",
    "            x = layers.SimpleRNN(units=units, activation=activation, return_sequences=True, stateful=False)(x)\n",
    "        \n",
    "        elif layer_type == 'lstm':\n",
    "            x = layers.LSTM(units=units, activation=activation, return_sequences=True, stateful=False)(x)\n",
    "        \n",
    "        elif layer_type == 'attention':\n",
    "            # Self-attention mechanism\n",
    "            x = layers.Attention()([x, x])\n",
    "\n",
    "    # Add the output layer\n",
    "    if params['output_layer'] == 'dense':\n",
    "        outputs = layers.Dense(units=params['output_dimension'], activation=params['output_activation'])(x)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported output layer type: {}\".format(params['output_layer']))\n",
    "    \n",
    "    # Create the prediction model\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c3cdf9-e409-4409-b5d6-d972efb22657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with params_test\n",
    "prediction_model = build_prediction_model_from_params(params_test)\n",
    "prediction_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d559b3-ac26-42a8-a7b0-d3c82680c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model.set_weights(model.get_weights())\n",
    "prediction_model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1915984d-9dac-4540-b8f4-30e360828f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = prediction_model.predict(rnn_dat.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264320df-baec-4847-af83-8c2bd36eb490",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c327f70-70e2-46a6-b58e-3608bcef252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_diff = np.square(preds - rnn_dat.y_test)\n",
    "mse = np.mean(squared_diff, axis=(1, 2))\n",
    "errs = np.sqrt(mse)\n",
    "errs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f19be-e6a2-440b-8326-9fe9ba76bb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7481b-b9a3-4eff-8771-ed13f8d48efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86a5e2-f8df-4bee-b0db-365e46e9a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN2():\n",
    "    \"\"\"\n",
    "    TEST\n",
    "    \"\"\"\n",
    "    def __init__(self, params: dict):\n",
    "        \"\"\"\n",
    "        Initializes the RNNModel with the given parameters.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        params : dict\n",
    "            A dictionary containing model parameters.\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        # Build model architectures based on input params\n",
    "        self.model_train = self._build_model_train()\n",
    "        self.model_predict = self._build_model_predict()\n",
    "        # Compile Models\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=self.params['learning_rate'])\n",
    "        self.model_train.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        self.model_predict.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    def _build_model_train(self):\n",
    "        params = self.params\n",
    "        \n",
    "        # Define the input layer with the specified batch size, timesteps, and features\n",
    "        inputs = tf.keras.Input(batch_shape=(params['batch_size'], params['timesteps'], params['n_features']))\n",
    "        x = inputs\n",
    "    \n",
    "        # Loop over each layer specified in 'hidden_layers'\n",
    "        for i, layer_type in enumerate(params['hidden_layers']):\n",
    "            units = params['hidden_units'][i]\n",
    "            activation = params['hidden_activation'][i]\n",
    "    \n",
    "            if layer_type == 'dense':\n",
    "                x = layers.Dense(units=units, activation=activation)(x)\n",
    "    \n",
    "            elif layer_type == 'dropout':\n",
    "                x = layers.Dropout(params['dropout'])(x)\n",
    "            \n",
    "            elif layer_type == 'rnn':\n",
    "                x = layers.SimpleRNN(units=units, activation=activation, dropout=params['dropout'], recurrent_dropout=params['recurrent_dropout'],\n",
    "                                     return_sequences=True, stateful=True)(x)\n",
    "            \n",
    "            elif layer_type == 'lstm':\n",
    "                x = layers.LSTM(units=units, activation=activation, dropout=params['dropout'], recurrent_dropout=params['recurrent_dropout'],\n",
    "                                return_sequences=True, stateful=True)(x)    \n",
    "            \n",
    "            elif layer_type == 'attention':\n",
    "                # Self-attention mechanism\n",
    "                x = layers.Attention()([x, x])\n",
    "    \n",
    "        # Add the output layer\n",
    "        if params['output_layer'] == 'dense':\n",
    "            outputs = layers.Dense(units=params['output_dimension'], activation=params['output_activation'])(x)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported output layer type: {}\".format(params['output_layer']))\n",
    "        \n",
    "        # Create the model\n",
    "        model = models.Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "\n",
    "    def _build_model_predict(self, return_sequences=True):\n",
    "        params = self.params\n",
    "        \n",
    "        # Define the input layer with flexible batch size and sequence length\n",
    "        inputs = tf.keras.Input(shape=(None, params['n_features']))\n",
    "        x = inputs\n",
    "    \n",
    "        # Loop over each layer specified in 'hidden_layers'\n",
    "        for i, layer_type in enumerate(params['hidden_layers']):\n",
    "            units = params['hidden_units'][i]\n",
    "            activation = params['hidden_activation'][i]\n",
    "            \n",
    "            if layer_type == 'dense':\n",
    "                x = layers.Dense(units=units, activation=activation)(x)\n",
    "    \n",
    "            elif layer_type == 'rnn':\n",
    "                x = layers.SimpleRNN(units=units, activation=activation, return_sequences=True, stateful=False)(x)\n",
    "            \n",
    "            elif layer_type == 'lstm':\n",
    "                x = layers.LSTM(units=units, activation=activation, return_sequences=True, stateful=False)(x)\n",
    "            \n",
    "            elif layer_type == 'attention':\n",
    "                # Self-attention mechanism\n",
    "                x = layers.Attention()([x, x])\n",
    "    \n",
    "        # Add the output layer\n",
    "        if params['output_layer'] == 'dense':\n",
    "            outputs = layers.Dense(units=params['output_dimension'], activation=params['output_activation'])(x)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported output layer type: {}\".format(params['output_layer']))\n",
    "        \n",
    "        # Create the prediction model\n",
    "        model = models.Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "\n",
    "    def is_stateful(self):\n",
    "        \"\"\"\n",
    "        Checks whether any of the layers in the internal model (self.model_train) are stateful.\n",
    "\n",
    "        Returns:\n",
    "        bool: True if at least one layer in the model is stateful, False otherwise.\n",
    "        \n",
    "        This method iterates over all the layers in the model and checks if any of them\n",
    "        have the 'stateful' attribute set to True. This is useful for determining if \n",
    "        the model is designed to maintain state across batches during training.\n",
    "\n",
    "        Example:\n",
    "        --------\n",
    "        model.is_stateful()\n",
    "        \"\"\"          \n",
    "        for layer in self.model_train.layers:\n",
    "            if hasattr(layer, 'stateful') and layer.stateful:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def plot_history(self, history, plot_title, create_figure=True):\n",
    "        \"\"\"\n",
    "        Plots the training history. Uses log scale on y axis for readability.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        history : History object\n",
    "            The training history object from model fitting. Output of keras' .fit command\n",
    "        plot_title : str\n",
    "            The title for the plot.\n",
    "        \"\"\"\n",
    "        \n",
    "        if create_figure:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "        plt.semilogy(history.history['loss'], label='Training loss')\n",
    "        if 'val_loss' in history.history:\n",
    "            plt.semilogy(history.history['val_loss'], label='Validation loss')\n",
    "        plt.title(f'{plot_title} Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose_fit = False, verbose_weights=False, \n",
    "            plot_history=True, plot_title = '', \n",
    "            weights=None, callbacks=[], validation_data=None, return_epochs=False, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Trains the model on the provided training data. Uses the fit method of the training model and then copies the weights over to the prediction model, which has a less restrictive input shape. Formats a list of callbacks to use within the fit method based on params input\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_train : np.ndarray\n",
    "            The input matrix data for training.\n",
    "        y_train : np.ndarray\n",
    "            The target vector data for training.\n",
    "        plot_history : bool, optional\n",
    "            If True, plots the training history. Default is True.\n",
    "        plot_title : str, optional\n",
    "            The title for the training plot. Default is an empty string.\n",
    "        weights : optional\n",
    "            Initial weights for the model. Default is None.\n",
    "        callbacks : list, optional\n",
    "            A list of callback functions to use during training. Default is an empty list.\n",
    "        validation_data : tuple, optional\n",
    "            Validation data to use during training, expected format (X_val, y_val). Default is None.\n",
    "        return_epochs : bool\n",
    "            If True, return the number of epochs that training took. Used to test and optimize early stopping\n",
    "        \"\"\"        \n",
    "        # Check Compatibility, assume features dimension is last in X_train array\n",
    "        if X_train.shape[-1] != self.params['n_features']:\n",
    "            raise ValueError(f\"X_train and number of features from params not equal. \\n X_train shape: {X_train.shape} \\n params['n_features']: {self.params['n_features']}. \\n Try recreating RNNData object with features list from params: `RNNData(..., features_list = parmas['features_list'])`\")\n",
    "        \n",
    "        # # verbose_fit argument is for printing out update after each epoch, which gets very long\n",
    "        # verbose_fit = self.params['verbose_fit'] \n",
    "        # verbose_weights = self.params['verbose_weights']\n",
    "        if verbose_weights:\n",
    "            print(f\"Training simple RNN with params: {self.params}\")\n",
    "            \n",
    "        # Setup callbacks\n",
    "        # if self.params[\"reset_states\"]:\n",
    "        #     callbacks=callbacks+[ResetStatesCallback(self.params), TerminateOnNaN()]\n",
    "\n",
    "        # Early stopping callback requires validation data\n",
    "        if validation_data is not None:\n",
    "            X_val, y_val = validation_data[0], validation_data[1]\n",
    "            print(\"Using early stopping callback.\")\n",
    "            early_stop = EarlyStoppingCallback(patience = self.params['early_stopping_patience'])\n",
    "            callbacks=callbacks+[early_stop]\n",
    "        if verbose_weights:\n",
    "            print(f\"Formatted X_train hash: {hash_ndarray(X_train)}\")\n",
    "            print(f\"Formatted y_train hash: {hash_ndarray(y_train)}\")\n",
    "            if validation_data is not None:\n",
    "                print(f\"Formatted X_val hash: {hash_ndarray(X_val)}\")\n",
    "                print(f\"Formatted y_val hash: {hash_ndarray(y_val)}\")\n",
    "            print(f\"Initial weights before training hash: {hash_weights(self.model_train)}\")\n",
    "\n",
    "        ## TODO: Hidden State Initialization\n",
    "        # Evaluate Model once to set nonzero initial state\n",
    "        # self.model_train(X_train[0:self.params['batch_size'],:,:])\n",
    "\n",
    "        if validation_data is not None:\n",
    "            history = self.model_train.fit(\n",
    "                X_train, y_train, \n",
    "                epochs=self.params['epochs'], \n",
    "                batch_size=self.params['batch_size'],\n",
    "                callbacks = callbacks,\n",
    "                verbose=verbose_fit,\n",
    "                validation_data = (X_val, y_val),\n",
    "                *args, **kwargs\n",
    "            )\n",
    "        else:\n",
    "            history = self.model_train.fit(\n",
    "                X_train, y_train, \n",
    "                epochs=self.params['epochs'], \n",
    "                batch_size=self.params['batch_size'],\n",
    "                callbacks = callbacks,\n",
    "                verbose=verbose_fit,\n",
    "                *args, **kwargs\n",
    "            )\n",
    "        \n",
    "        if plot_history:\n",
    "            self.plot_history(history,plot_title)\n",
    "            \n",
    "        if verbose_weights:\n",
    "            print(f\"Fitted Weights Hash: {hash_weights(self.model_train)}\")\n",
    "\n",
    "        # Update Weights for Prediction Model\n",
    "        w_fitted = self.model_train.get_weights()\n",
    "        self.model_predict.set_weights(w_fitted)\n",
    "\n",
    "        if return_epochs:\n",
    "            # Epoch counting starts at 0, adding 1 for the count\n",
    "            return early_stop.best_epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42459583-a634-4dd9-a94b-4535302f481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_test = {\n",
    "    'n_features': 3,\n",
    "    'timesteps': 12,\n",
    "    'batch_size': 32,\n",
    "    'hidden_layers': ['dense', 'lstm', 'attention', 'dense'],\n",
    "    'hidden_units': [64, 32, None, 32],\n",
    "    'hidden_activation': ['relu', 'tanh', None, 'relu'],\n",
    "    'dropout': 0.2,\n",
    "    'recurrent_dropout': 0.2,\n",
    "    'output_layer': 'dense',\n",
    "    'output_activation': 'linear',\n",
    "    'output_dimension': 1,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e7dc43-021c-4152-b1c5-dcf3ae25b5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1627f9-f011-4159-98a2-1b5973929e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = RNN2(params_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc66c0-ccb5-46c2-a073-1fa7a5be750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.model_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0bd69-aa76-4d7e-a4eb-3c7a800b6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.fit(rnn_dat.X_train, rnn_dat.y_train, verbose_fit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0398824-16aa-4f30-a2c2-6e53d54778c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_weights(mod.model_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed3cbd-b78e-4d8c-be61-c818055fb539",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_weights(mod.model_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282cb651-b21f-401d-94c5-9e07530a9ba8",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1894e3-5283-4e5e-83ae-9c386836a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib \n",
    "import moisture_rnn\n",
    "importlib.reload(moisture_rnn)\n",
    "from moisture_rnn import RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b690f-edaa-4c97-893c-ec9a3a615ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_yml(\"params.yaml\", subkey=\"lstm\")\n",
    "params = RNNParams(params)\n",
    "params.update({\n",
    "    'dense_layers': 2,\n",
    "    'dense_units': 32\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ab015-4e41-4255-8b1a-843b61e3d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.update({'batch_schedule_type': 'step'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38f35a-d367-4df8-b2d3-7691ff4b0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat = rnn_data_wrap(combine_nested(train3), params)\n",
    "reproducibility.set_seed(123)\n",
    "rnn = RNN(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade176b9-2844-43b6-b85e-5bb30414aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945e6c1-6b3a-4b7d-ade2-b5788860ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.model_train.fit(rnn_dat.X_train, rnn_dat.y_train, validation_data=(rnn_dat.X_val, rnn_dat.y_val), \n",
    "                    verbose=True, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d123b2b-047e-4a04-b49e-6629cc22edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.model_predict.set_weights(rnn.model_train.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db57df64-d2ac-4b91-bbfc-71a5834ddf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.model_predict.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466887f-9833-4a6a-a0c7-a4d56f207d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat.X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e630c-db69-4603-962e-95c576b45ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rnn.model_predict.predict(rnn_dat.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8228a9-5b6d-4de1-8968-d40277edacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b001dd8-ffd7-4fd1-bf11-413515ddc488",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat.X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c6dbf-6ca8-451e-abc4-b68b8116871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_diff = np.square(preds - rnn_dat.y_test)\n",
    "mse = np.mean(squared_diff, axis=(1, 2))\n",
    "errs = np.sqrt(mse)\n",
    "errs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef092ff-8af1-491a-b0bf-cc3e674330e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Phys Initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488628e-4552-4909-83e9-413fd6878bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.update({\n",
    "    'epochs':100,\n",
    "    'dense_layers': 0,\n",
    "    'activation': ['relu', 'relu'],\n",
    "    'phys_initialize': False,\n",
    "    'dropout': [0,0],\n",
    "    'space_fracs': [.8, .1, .1],\n",
    "    'scaler': None\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7db7d6-949e-457d-90b9-22d9c5aa4739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import moisture_rnn\n",
    "importlib.reload(moisture_rnn)\n",
    "from moisture_rnn import rnn_data_wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26cf1b2-2fad-409d-888f-4921b0ae4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['scaler'] is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4627bc-0f90-44e6-9103-2efe5c5f439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat = rnn_data_wrap(combine_nested(train3), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bdf26c-07e7-4e4a-a567-af7dd0f564d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed()\n",
    "rnn = RNN(params)\n",
    "m, errs = rnn.run_model(rnn_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01227b79-98f3-4931-bdfc-ff08afa8be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.model_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a8bf0-638b-4b4b-82fe-c6a1965a72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdbb3a-3e83-4541-93b2-982b6d4cbe93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn_dat.X_train[:,:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca41db1-72aa-44b6-b9dd-058735336ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592a4c9-cb3b-4174-8eaa-02afd00a1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat['features_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832fb05-417c-4648-8e2e-7748c06b3768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2360aef-e9c4-4a71-922d-336e53b82537",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4e441-9bf1-4d57-bb37-091553e23212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib \n",
    "import moisture_rnn\n",
    "importlib.reload(moisture_rnn)\n",
    "from moisture_rnn import RNN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ba896-e3be-4a9f-8a42-3df64aff7d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_yml(\"params.yaml\", subkey=\"lstm\")\n",
    "params = RNNParams(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf567e-d623-4e14-b578-eed88b80d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat = rnn_data_wrap(combine_nested(train3), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb5708-7be9-4474-abb4-3b7ff4bf79df",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.update({\n",
    "    'loc_batch_reset': rnn_dat.n_seqs # Used to reset hidden state when location changes for a given batch\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0157a6bc-3a99-4b87-a42c-ab770d19ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moisture_rnn import ResetStatesCallback, EarlyStoppingCallback\n",
    "params.update({'epochs': 50, 'learning_rate': 0.001, 'verbose_fit': True, 'rnn_layers': 2, 'rnn_units': 20, 'dense_layers': 1, 'dense_units': 10,\n",
    "              'activation': ['tanh', 'tanh'], 'features_list': rnn_dat.features_list,\n",
    "              'batch_schedule_type':'step', 'bmin': 10, 'bmax':rnn_dat.hours})\n",
    "reproducibility.set_seed(123)\n",
    "lstm = RNN_LSTM(params)\n",
    "\n",
    "history = lstm.model_train.fit(rnn_dat.X_train, rnn_dat.y_train, \n",
    "                    batch_size = params['batch_size'], epochs=params['epochs'], \n",
    "                    callbacks = [ResetStatesCallback(params),\n",
    "                                EarlyStoppingCallback(patience = 15)],\n",
    "                   validation_data = (rnn_dat.X_val, rnn_dat.y_val))\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c8d8d-ea50-44ea-8c0c-414e07cd01ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03063e3c-e8f4-451d-b0cf-25bd965cd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = RNNParams(read_yml(\"params.yaml\", subkey=\"lstm\"))\n",
    "params.update({'epochs': 50, 'learning_rate': 0.001, 'verbose_fit': True, 'rnn_layers': 2, 'rnn_units': 20, 'dense_layers': 1, 'dense_units': 10,\n",
    "              'activation': ['tanh', 'tanh'], 'features_list': rnn_dat.features_list,\n",
    "              'batch_schedule_type':'step', 'bmin': 10, 'bmax':rnn_dat.hours})\n",
    "rnn_dat = rnn_data_wrap(combine_nested(train3), params)\n",
    "params.update({\n",
    "    'loc_batch_reset': rnn_dat.n_seqs # Used to reset hidden state when location changes for a given batch\n",
    "})\n",
    "reproducibility.set_seed(123)\n",
    "lstm = RNN_LSTM(params)\n",
    "m, errs = lstm.run_model(rnn_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46a2dc-bf5c-4893-a1ee-a1682566f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f319f37-7d13-41fd-95fa-66dbdfeab588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1252b08-62b9-4d24-add2-0f87d15b0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = RNNParams(read_yml(\"params.yaml\", subkey=\"rnn\"))\n",
    "rnn_dat = rnn_data_wrap(combine_nested(train3), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281540b-eb26-4923-883b-1b31d8347634",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "rnn = RNN(params)\n",
    "m, errs = rnn.run_model(rnn_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0269b4-d6b7-4f20-8386-69814d7acaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b44de3-a0e9-49e4-9e03-873d69580c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f4fee4-7fce-49c5-a455-97a90b754c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d4b26-641e-47b2-a90a-67cd32215d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
