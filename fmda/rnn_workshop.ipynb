{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc7920-e380-4b81-bac0-cd6840450e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# Local modules\n",
    "sys.path.append('..')\n",
    "import reproducibility\n",
    "from utils import print_dict_summary\n",
    "from data_funcs import load_and_fix_data, rmse\n",
    "from moisture_rnn import RNN, create_rnn_data2\n",
    "from moisture_rnn_pkl import pkl2train\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from utils import hash2\n",
    "import copy\n",
    "import logging\n",
    "from utils import logging_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e8839-bf0e-4995-b966-c09e4df001ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2298a1a1-b72c-4c7e-bcb6-2cdefe96fe3e",
   "metadata": {},
   "source": [
    "## Test Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56444dda-1e57-4b47-ad35-72ae7ed706e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"params.yaml\") as file:\n",
    "    params = yaml.safe_load(file)[\"rnn\"]\n",
    "params.update({'scale': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0539f62-a8bc-4292-ab16-ca639f2b37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import moisture_rnn_pkl\n",
    "# importlib.reload(moisture_rnn_pkl)\n",
    "# from moisture_rnn_pkl import pkl2train\n",
    "# import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666d11f-aaa2-426e-a406-70603f2799f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pkl2train(['data/reproducibility_dict2.pickle', \"data/test_CA_202401.pkl\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1c7ad-6529-4c34-8444-0ef11f44dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = copy.deepcopy(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3c25a-cf08-4a6d-be2e-21afb861c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat = create_rnn_data2(train['reproducibility'], params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ad412-1cae-47ad-a2c9-de9e40c30061",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed()\n",
    "rnn = RNN(params2)\n",
    "rnn.run_model(rnn_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a3591-e20e-42ce-b55f-32ae285e7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f593ea9-40b5-46c5-a217-b41ed150bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat = create_rnn_data2(train['CNFC1_202401'], params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1147c-e882-4b67-9e77-36a3b4b8bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed()\n",
    "rnn = RNN(params2)\n",
    "rnn.run_model(rnn_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2360aef-e9c4-4a71-922d-336e53b82537",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a73c40-0bab-4aa0-8265-00f427aa97ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Input, Dropout, Dense, SimpleRNN\n",
    "from moisture_rnn import staircase_2\n",
    "from abc import ABC, abstractmethod\n",
    "class RNNModel(ABC):\n",
    "    def __init__(self, params: dict):\n",
    "        self.params = params\n",
    "        if type(self) is RNNModel:\n",
    "            raise TypeError(\"MLModel is an abstract class and cannot be instantiated directly\")\n",
    "        super().__init__()\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X_train, y_train, weights=None):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "    def run_model(self, dict0):\n",
    "        # Make copy to prevent changing in place\n",
    "        dict1 = copy.deepcopy(dict0)\n",
    "        # Extract Fields\n",
    "        X_train, y_train, X_test, y_test = dict1['X_train'].copy(), dict1['y_train'].copy(), dict1[\"X_test\"].copy(), dict1['y_test'].copy()\n",
    "        case_id = dict1['case']\n",
    "        # Fit model\n",
    "        self.fit(X_train, y_train)\n",
    "        # Generate Predictions, \n",
    "        # run through training to get hidden state set proporly for forecast period\n",
    "        X = np.concatenate((X_train, X_test))\n",
    "        y = np.concatenate((y_train, y_test)).flatten()\n",
    "        # Predict\n",
    "        print(f\"Predicting Training through Test \\n features hash: {hash2(X)} \\n response hash: {hash2(y)} \")\n",
    "        m = self.predict(X).flatten()\n",
    "        dict1['m']=m\n",
    "        dict0['m']=m # add to outside env dictionary, should be only place this happens\n",
    "        if self.params['scale']:\n",
    "            print(f\"Rescaling data using {self.params['scaler']}\")\n",
    "            if self.params['scaler'] == \"reproducibility\":\n",
    "                m  *= self.params['scale_fm']\n",
    "                y  *= self.params['scale_fm']\n",
    "                y_train *= self.params['scale_fm']\n",
    "                y_test *= self.params['scale_fm']\n",
    "        # Check Reproducibility, TODO: old dict calls it hidden_units not rnn_units, so this doens't check that\n",
    "        if (case_id == \"reproducibility\") and compare_dicts(self.params, repro_hashes['params'], ['epochs', 'batch_size', 'scale', 'activation', 'learning_rate']):\n",
    "            print(\"Checking Reproducibility\")\n",
    "            checkm = m[350]\n",
    "            hv = hash2(self.model_predict.get_weights())\n",
    "            if self.params['phys_initialize']:\n",
    "                hv5 = repro_hashes['phys_initialize']['fitted_weight_hash']\n",
    "                mv = repro_hashes['phys_initialize']['predictions_hash']\n",
    "            else:\n",
    "                hv5 = repro_hashes['rand_initialize']['fitted_weight_hash']\n",
    "                mv = repro_hashes['rand_initialize']['predictions_hash']           \n",
    "            \n",
    "            print(f\"Fitted weights hash (check 5): {hv}, Reproducibility weights hash: {hv5}, Error: {hv5-hv}\")\n",
    "            print(f\"Model predictions hash: {checkm}, Reproducibility preds hash: {mv}, Error: {mv-checkm}\")\n",
    "        \n",
    "        # Plot final fit and data\n",
    "        # TODO: make plot_data specific to this context\n",
    "        dict1['y'] = y\n",
    "        plot_data(dict1, title=\"RNN\", title2=dict1['case'])\n",
    "        \n",
    "        # Calculate Errors\n",
    "        err = rmse(m, y)\n",
    "        h2 = X_train.shape[0] # index of final training set value\n",
    "        err_train = rmse(m[:h2], y_train.flatten())\n",
    "        err_pred = rmse(m[h2:], y_test.flatten())\n",
    "        rmse_dict = {\n",
    "            'all': err, \n",
    "            'training': err_train, \n",
    "            'prediction': err_pred\n",
    "        }\n",
    "        return rmse_dict\n",
    "        \n",
    "class ResetStatesCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model.reset_states()\n",
    "\n",
    "\n",
    "class RNN_LSTM(RNNModel):\n",
    "    def __init__(self, params, loss='mean_squared_error'):\n",
    "        super().__init__(params)\n",
    "        self.model_train = self._build_model_train()\n",
    "        self.model_predict = self._build_model_predict()\n",
    "\n",
    "    def _build_model_train(self, return_sequences=False):\n",
    "        inputs = tf.keras.Input(batch_shape=self.params['batch_shape'])\n",
    "        x = inputs\n",
    "        for i in range(self.params['rnn_layers']):\n",
    "            x = LSTM(\n",
    "                units=self.params['rnn_units'],\n",
    "                activation=self.params['activation'][0],\n",
    "                dropout=self.params[\"dropout\"][0],\n",
    "                stateful=self.params['stateful'],\n",
    "                return_sequences=return_sequences)(x)\n",
    "        if self.params[\"dropout\"][1] > 0:\n",
    "            x = Dropout(self.params[\"dropout\"][1])(x)            \n",
    "        for i in range(self.params['dense_layers']):\n",
    "            x = Dense(self.params['dense_units'], activation=self.params['activation'][1])(x)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=self.params['learning_rate'])\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        \n",
    "        if self.params[\"verbose_weights\"]:\n",
    "            print(f\"Initial Weights Hash: {hash2(model.get_weights())}\")\n",
    "        return model\n",
    "    def _build_model_predict(self, return_sequences=True):\n",
    "        \n",
    "        inputs = tf.keras.Input(shape=self.params['pred_input_shape'])\n",
    "        x = inputs\n",
    "        for i in range(self.params['rnn_layers']):\n",
    "            x = LSTM(\n",
    "                units=self.params['rnn_units'],\n",
    "                activation=self.params['activation'][0],\n",
    "                stateful=False,return_sequences=return_sequences)(x)\n",
    "        for i in range(self.params['dense_layers']):\n",
    "            x = Dense(self.params['dense_units'], activation=self.params['activation'][1])(x)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=self.params['learning_rate'])\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)  \n",
    "\n",
    "        # Set Weights to model_train\n",
    "        w_fitted = self.model_train.get_weights()\n",
    "        model.set_weights(w_fitted)\n",
    "        \n",
    "        return model\n",
    "    def format_train_data(self, X, y, verbose=False):\n",
    "        X, y = staircase_2(X, y, timesteps = self.params[\"timesteps\"], batch_size=self.params[\"batch_size\"], verbose=verbose)\n",
    "        return X, y\n",
    "    def format_pred_data(self, X):\n",
    "        return np.reshape(X,(1, X.shape[0], self.params['features']))\n",
    "    def fit(self, X_train, y_train, plot=True, plot_title = '', \n",
    "            weights=None, callbacks=[], verbose_fit=None, validation_data=None, *args, **kwargs):\n",
    "        # verbose_fit argument is for printing out update after each epoch, which gets very long\n",
    "        # These print statements at the top could be turned off with a verbose argument, but then\n",
    "        # there would be a bunch of different verbose params\n",
    "        print(f\"Training simple RNN with params: {self.params}\")\n",
    "        X_train, y_train = self.format_train_data(X_train, y_train)\n",
    "        print(f\"X_train hash: {hash2(X_train)}\")\n",
    "        print(f\"y_train hash: {hash2(y_train)}\")\n",
    "        if validation_data is not None:\n",
    "            X_val, y_val = self.format_train_data(validation_data[0], validation_data[1])\n",
    "            print(f\"X_val hash: {hash2(X_val)}\")\n",
    "            print(f\"y_val hash: {hash2(y_val)}\")\n",
    "        print(f\"Initial weights before training hash: {hash2(self.model_train.get_weights())}\")\n",
    "        # Setup callbacks\n",
    "        if self.params[\"reset_states\"]:\n",
    "            callbacks=callbacks+[ResetStatesCallback()]\n",
    "        \n",
    "        # Note: we overload the params here so that verbose_fit can be easily turned on/off at the .fit call \n",
    "        if verbose_fit is None:\n",
    "            verbose_fit = self.params['verbose_fit']\n",
    "        # Evaluate Model once to set nonzero initial state\n",
    "        if self.params[\"batch_size\"]>= X_train.shape[0]:\n",
    "            self.model_train(X_train)\n",
    "        if validation_data is not None:\n",
    "            history = self.model_train.fit(\n",
    "                X_train, y_train+self.params['centering'][1], \n",
    "                epochs=self.params['epochs'], \n",
    "                batch_size=self.params['batch_size'],\n",
    "                callbacks = callbacks,\n",
    "                verbose=verbose_fit,\n",
    "                validation_data = (X_val, y_val),\n",
    "                *args, **kwargs\n",
    "            )\n",
    "        else:\n",
    "            history = self.model_train.fit(\n",
    "                X_train, y_train+self.params['centering'][1], \n",
    "                epochs=self.params['epochs'], \n",
    "                batch_size=self.params['batch_size'],\n",
    "                callbacks = callbacks,\n",
    "                verbose=verbose_fit,\n",
    "                *args, **kwargs\n",
    "            )\n",
    "        if plot:\n",
    "            self.plot_history(history,plot_title)\n",
    "        if self.params[\"verbose_weights\"]:\n",
    "            print(f\"Fitted Weights Hash: {hash2(self.model_train.get_weights())}\")\n",
    "\n",
    "        # Update Weights for Prediction Model\n",
    "        w_fitted = self.model_train.get_weights()\n",
    "        self.model_predict.set_weights(w_fitted)\n",
    "    def predict(self, X_test):\n",
    "        print(\"Predicting with simple RNN\")\n",
    "        X_test = self.format_pred_data(X_test)\n",
    "        preds = self.model_predict.predict(X_test).flatten()\n",
    "        return preds\n",
    "\n",
    "\n",
    "    def plot_history(self, history, plot_title):\n",
    "        plt.semilogy(history.history['loss'], label='Training loss')\n",
    "        if 'val_loss' in history.history:\n",
    "            plt.semilogy(history.history['val_loss'], label='Validation loss')\n",
    "        plt.title(f'{plot_title} Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3ee62-4bef-4eb9-a599-405beaa0632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dat = create_rnn_data2(train['reproducibility'],params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b05a3-8788-4fcb-9a8b-3c8c28426803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Input, Dropout, Dense\n",
    "reproducibility.set_seed()\n",
    "lstm = RNN_LSTM(params)\n",
    "lstm.fit(rnn_dat[\"X_train\"], rnn_dat[\"y_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4e441-9bf1-4d57-bb37-091553e23212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d7ae31-e3fb-4a44-95bd-093ec34e0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Input, Dropout, Dense\n",
    "reproducibility.set_seed()\n",
    "lstm = RNN_LSTM(params)\n",
    "lstm.fit(rnn_dat[\"X_train\"], rnn_dat[\"y_train\"],\n",
    "        recurrent_activation=\"sigmoid\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9d612e-8cd2-40ca-a789-91c99c3d6ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a24c6-9a67-45aa-bc5c-8818aa0ca049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
