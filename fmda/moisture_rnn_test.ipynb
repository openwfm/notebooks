{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f51f7f4",
   "metadata": {},
   "source": [
    "## Testing staircase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a797f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moisture_rnn import staircase, staircase_2\n",
    "import numpy as np\n",
    "from data_funcs import plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b801e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data shape   [batches,batch_size, sequence_length, features] \n",
    "# also called           [samples,timesteps,features]\n",
    "# input data size       [trainsteps,features] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9218f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints=10\n",
    "timesteps=3\n",
    "features=1\n",
    "outputs=1\n",
    "x=np.tile(range(datapoints), (features, 1)).T\n",
    "y=np.tile(range(datapoints), (outputs, 1)).T\n",
    "# print('x =',x)\n",
    "print('x shape =',x.shape)\n",
    "# print('y =',y)\n",
    "print('y shape =',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5874621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the original staircase, offset by one, all in one batch, no hidden state passed\n",
    "x_train, y_train = staircase(x,y,timesteps,datapoints,return_sequences=False, verbose = True)\n",
    "print('x_train shape =',x_train.shape)\n",
    "print('y_train shape =',y_train.shape)\n",
    "# print('x_train =',x_train)\n",
    "# print('y_train =',y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new staircase, hidden state passed between batches\n",
    "x_train, y_train = staircase_2(x,y,timesteps,batch_size=3,return_sequences=False, verbose = True)\n",
    "print('x_train shape =',x_train.shape)\n",
    "print('y_train shape =',y_train.shape)\n",
    "print('x_train =',x_train)\n",
    "print('y_train =',y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230abb62",
   "metadata": {},
   "source": [
    "## Testing RNN training on time lag problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, SimpleRNN\n",
    "from data_funcs import plot_data\n",
    "\n",
    "# Generate sample time series data (replace with your actual data)\n",
    "hours = 500  #Ensure divisible by batch size and lookback\n",
    "x = 10*(1+np.cos(np.linspace(0, hours, hours)*2*np.pi/24))  # daily\n",
    "x = x+5*np.exp(np.sin(np.linspace(0, hours, hours)*2*np.pi/240))# 10 day cycle\n",
    "x = x + 1.0*np.random.randn(*x.shape) # random\n",
    "x = x/35\n",
    "y = np.zeros((hours))\n",
    "z = np.zeros((hours))\n",
    "for i in range(1,hours):\n",
    "    y[i] = y[i-1] + (x[i-1] - y[i-1])/10.\n",
    "    z[i] = z[i-1] + (x[i-1] - z[i-1])/3.\n",
    "y = (y + z)/2\n",
    "x=np.reshape(x,[-1,1])\n",
    "y=np.reshape(y,[-1,1])\n",
    "print('x.shape',x.shape)\n",
    "print('y.shape',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc470846",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data({'E':x,'m':y},title=\"Generated equilibrium  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12e812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data with lookback, offset by one, all one batch\n",
    "x_train, y_train = [], []\n",
    "timesteps = 10\n",
    "for i in range(len(x) - timesteps):\n",
    "    x_train.append(x[i:i+timesteps])  # Create sequences of 5 timesteps\n",
    "    y_train.append(y[i+timesteps])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Reshape input data for RNN\n",
    "x_train = x_train.reshape(-1, timesteps, 1)  # Print x_train.shape to verify\n",
    "print(x_train)\n",
    "print('x_train.shape',x_train.shape)\n",
    "print('y_train.shape',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f5b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "x_train, y_train = staircase_2(x,y,timesteps,batch_size,return_sequences=False, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35076792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class ResetStatesCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model.reset_states()\n",
    "        \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Instantiate an optimizer with a custom learning rate\n",
    "optimizer = Adam(learning_rate=0.001)  \n",
    "\n",
    "# Define the stateful RNN model\n",
    "RNN=SimpleRNN\n",
    "#RNN=LSTM\n",
    "#RNN=GRU\n",
    "epochs=50\n",
    "activation='tanh'\n",
    "activation='linear'\n",
    "cells=1\n",
    "training = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(RNN(cells, stateful=True, batch_input_shape=(batch_size, timesteps, 1),activation=activation))  \n",
    "model.add(Dense(1))  # Output layer for single-value prediction\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "# Train the model (manual state resetting)'print('x_train.shape',x_train.shape)\n",
    "print('x_train.shape',x_train.shape)\n",
    "print('y_train.shape',y_train.shape)\n",
    "\n",
    "if training == 1:\n",
    "    for i in range(epochs):\n",
    "        model.fit(x_train, y_train, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "elif training == 2:\n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, shuffle=False, \n",
    "              callbacks=[ResetStatesCallback()])\n",
    "elif training == 3:\n",
    "    sequences = x_train.shape[0]\n",
    "    batches = sequences // batch_size\n",
    "    print('x_train has',sequences,'sequences',batches,'batches')\n",
    "    for i in range(epochs):\n",
    "        for j in range(batches):\n",
    "            print('iteration',i,'batch',j,'size',batch_size)\n",
    "            batch_start = j*batch_size\n",
    "            batch_next = batch_start + batch_size \n",
    "            model.fit(x_train[batch_start:batch_next], y_train[batch_start:batch_next], \n",
    "                      epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()  # at the end of each iteration = epoch\n",
    "else:\n",
    "    raise ValueError('training must be 1 or 2 or 3')\n",
    "# print('weights',model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ad215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stateless RNN model - to be used on data in a single sequence\n",
    "model2 = Sequential()\n",
    "model2.add(RNN(cells, stateful=False,input_shape=(None,1),activation=activation)) \n",
    "model2.add(Dense(1))  # Output layer for single-value prediction\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# transfer weights, predict, plot\n",
    "w=model.get_weights()\n",
    "model2.set_weights(w)\n",
    "z = model2.predict(x.reshape((-1,1))) # inout and output need to be shape (-1,1), ie columns\n",
    "plot_data({'x':x,'y':y,'z':z},xlabel='',ylabel='',title='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22ab512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd53a91d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
