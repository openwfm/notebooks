{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55248b75-ad0a-4a9d-9ebb-6ffbdfe7b429",
   "metadata": {},
   "source": [
    "# Gather HRRR Atmospheric Data\n",
    "\n",
    "The purpose of this notebook is to demonstrate the package functions from `gather_HRRR`, intended to build time series of atmospheric observations at an arbitrary longitude/latitude coordinate in North America. The data source is the NOAA HRRR product from AWS. See the list of variables [here](https://www.nco.ncep.noaa.gov/pmb/products/hrrr/hrrr.t00z.wrfsfcf00.grib2.shtml).\n",
    "\n",
    "The time series are intended for development and training an ML model of fuel moisture content (FMC). For live deploying an atmospheric model across the country, see the Herbie python package: \n",
    "\n",
    "https://github.com/blaylockbk/Herbie/tree/main/herbie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28b796-4661-4a6a-a84e-14fcba89fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "## Packages\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import date, timedelta, datetime\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "## Local modules with very literal names\n",
    "from gather_HRRR import extract_hrrr, gather_hrrr_time_range, download_grib, slice_hrrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b15c682-1224-43bc-89dc-67ec799e6edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# Import from parent dir\n",
    "parent_path1 = osp.dirname((osp.realpath(\"__file__\")))\n",
    "parent_path2 = osp.dirname(osp.dirname((osp.realpath(\"__file__\"))))\n",
    "sys.path.append(parent_path1)\n",
    "sys.path.append(parent_path2)\n",
    "\n",
    "from data_funcs import to_json, from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb903b3d-4d69-4693-adbb-7d863063ae6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create config json file for later use\n",
    "# Time period of 3 hours in June 2022\n",
    "hrrr_config = {\n",
    "    'start_time': \"2022-06-01 00:00\",\n",
    "    'end_time': \"2022-06-01 02:00\",\n",
    "    'dest_dir': \"\" # optional subdir string, needs more tests\n",
    "}\n",
    "\n",
    "to_json(hrrr_config, \"hrrr_conf.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fedaaf-97fa-4626-b3dd-951f0d06172d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time period of 6 hours in June 2022\n",
    "start_time = \"2022-06-01 00:00\"\n",
    "end_time = \"2022-06-01 05:00\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8556fbc0-4295-4229-90a8-4f48379d8a29",
   "metadata": {},
   "source": [
    "## Coordinates of Interest\n",
    "\n",
    "Read in data frame of latitude and longitude coordinates that correspond to RAWS station locations. These locations have sensors for FMC, the primary response variable of interest in this larger project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d8d7e-6164-4934-900a-8cae98c91e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in list of RAWS Stations\n",
    "df = pd.read_csv(\"raws_stations_WA.csv\")\n",
    "\n",
    "# Filter to those with complete fmda data\n",
    "df = df[(df[['air_temp', 'relative_humidity', 'precip_accum',\n",
    "       'fuel_moisture', 'wind_speed', 'solar_radiation']]==1).sum(axis=1)==6]\n",
    "\n",
    "# Get first 10 rows for demo\n",
    "df = df[0:10]\n",
    "\n",
    "# Get list of coords\n",
    "points = list(df[[\"lon\",\"lat\"]].itertuples(index=False,name=None))\n",
    "names = np.unique(df['STID'])\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d2cc3-9c05-46a8-bdce-d6830198b4bd",
   "metadata": {},
   "source": [
    "## DEMO: Download HRRR Grib\n",
    "\n",
    "Given a single time slice, download the corresponding surface level HRRR model file from AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c435dfe-abd2-440e-8221-7ac65055c7c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tempfile, url = download_grib(\n",
    "    source_url = \"https://noaa-hrrr-bdp-pds.s3.amazonaws.com\",\n",
    "    time = end_time,\n",
    "    model = \"wrfsfcf\",\n",
    "    dest_dir =  \".\" # destination subdirectory for url content\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767fc62d-ed82-409f-930e-13cb501b5c9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract Atmospheric Data\n",
    "\n",
    "Variables of interest and their associated HRRR layer are:\n",
    "* Temperature: \"t2m\", 2m layer\n",
    "* RH: \"r2\", 2m layer\n",
    "* Rain: \"\", surface layer\n",
    "    - \"PRATE\", \"APCP\"\n",
    "* Solar Radiation: \"\", surface layer\n",
    "    - \"DSWRF\", downward short-wave flux\n",
    "    - \"USWRF\", upward short-wave\n",
    "    - \"DLWRF\", upward long-wave\n",
    "    - \"ULWRF\", upward long-wave\n",
    "* Wind: \"\", 10m layer\n",
    "    - \"u10\": Eastward component of wind\n",
    "    - \"v10\": Northward ncomponent of wind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a3aab7-b078-4252-96fe-e0c2e064975e",
   "metadata": {},
   "source": [
    "### Manually Extract and Plot\n",
    "\n",
    "This section demonstrates how to extract atmospheric data and plots it to show nearest neighbors methodology (modified B. Blaylock source below).\n",
    "\n",
    "This gets the 2m variables of interest, so it just gets temp and RH. Code modified from B. Blaylock: https://stackoverflow.com/questions/58758480/xarray-select-nearest-lat-lon-with-multi-dimension-coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593261e-a8ce-491d-af04-91117979efde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in temp downloaded file from before at 2m level\n",
    "ds=xr.open_dataset(\n",
    "    tempfile,\n",
    "    filter_by_keys={'typeOfLevel': 'heightAboveGround', 'level': 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9a93b-1ba1-451e-beae-5352e3245871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Desired Lat/Lon pt\n",
    "lon = points[0][0]\n",
    "lat = points[0][1]\n",
    "# Convert to degrees east if HRRR formatted that way\n",
    "if ds.longitude.attrs['units']==\"degrees_east\":\n",
    "    lon = 360 + lon\n",
    "    # print(lon)\n",
    "    \n",
    "# Code modified from B. Blaylock https://stackoverflow.com/questions/58758480/xarray-select-nearest-lat-lon-with-multi-dimension-coordinates\n",
    "ds.t2m.plot(x='longitude', y='latitude')\n",
    "\n",
    "abslat = np.abs(ds.latitude-lat)\n",
    "abslon = np.abs(ds.longitude-lon)\n",
    "c = np.maximum(abslon, abslat)\n",
    "\n",
    "([xloc], [yloc]) = np.where(c == np.min(c))\n",
    "\n",
    "# Now I can use that index location to get the values at the x/y diminsion\n",
    "point_ds = ds.sel(x=yloc, y=xloc)\n",
    "\n",
    "# Plot requested lat/lon point blue\n",
    "plt.scatter(lon, lat, color='b')\n",
    "plt.text(lon, lat, 'requested')\n",
    "\n",
    "# Plot nearest point in the array red\n",
    "g=plt.scatter(point_ds.longitude, point_ds.latitude, color='r')\n",
    "g.set_facecolor('none')\n",
    "plt.text(point_ds.longitude, point_ds.latitude, 'nearest')\n",
    "\n",
    "plt.title('temp at nearest point: %s' % point_ds.t2m.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b813c-b0a7-4593-8c48-179ef2b10ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Desired Lat/Lon pt\n",
    "lon = points[9][0]\n",
    "lat = points[9][1]\n",
    "# Convert to degrees east if HRRR formatted that way\n",
    "if ds.longitude.attrs['units']==\"degrees_east\":\n",
    "    lon = 360 + lon\n",
    "    # print(lon)|\n",
    "    \n",
    "# Code modified from B. Blaylock https://stackoverflow.com/questions/58758480/xarray-select-nearest-lat-lon-with-multi-dimension-coordinates\n",
    "ds.t2m.plot(x='longitude', y='latitude')\n",
    "\n",
    "abslat = np.abs(ds.latitude-lat)\n",
    "abslon = np.abs(ds.longitude-lon)\n",
    "c = np.maximum(abslon, abslat)\n",
    "\n",
    "([xloc], [yloc]) = np.where(c == np.min(c))\n",
    "\n",
    "# Now I can use that index location to get the values at the x/y diminsion\n",
    "point_ds = ds.sel(x=yloc, y=xloc)\n",
    "\n",
    "# Plot requested lat/lon point blue\n",
    "plt.scatter(lon, lat, color='b')\n",
    "plt.text(lon, lat, 'requested')\n",
    "\n",
    "# Plot nearest point in the array red\n",
    "g=plt.scatter(point_ds.longitude, point_ds.latitude, color='r')\n",
    "g.set_facecolor('none')\n",
    "plt.text(point_ds.longitude, point_ds.latitude, 'nearest')\n",
    "\n",
    "plt.title('temp at nearest point: %s' % point_ds.t2m.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3935e8-da24-454e-97a5-d706f3910b51",
   "metadata": {},
   "source": [
    "### Extract Atmospheric Data with Module Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443c5c1-61a1-4b54-a877-85abc1163a73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gather_HRRR import west_to_east\n",
    "\n",
    "def extract_hrrr(ds, coord, convert_EW=True):\n",
    "    ## Get variables from the given HRRR layer\n",
    "    ## Vars include: temp (k), RH\n",
    "    # ds: xarray object from HRRR, layer could be 2m, 10m, surface\n",
    "    # coord: tuple of the form (lon, lat)\n",
    "    # convert_EW: whether or not to convert longitude from E to W. Default True to make compatible with RAWS data\n",
    "\n",
    "    if ds.longitude.attrs['units']==\"degrees_east\" and convert_EW:\n",
    "        coord = west_to_east(coord)\n",
    "        # print('Converting target longitude to Deg. E')\n",
    "    \n",
    "    lon = coord[0][0]\n",
    "    lat = coord[0][1]\n",
    "    \n",
    "    abslat = np.abs(ds.latitude-lat)\n",
    "    abslon = np.abs(ds.longitude-lon)\n",
    "    c = np.maximum(abslon, abslat)\n",
    "\n",
    "    ([xloc], [yloc]) = np.where(c == np.min(c))\n",
    "\n",
    "    # use that index location to get the values, \n",
    "    # NOTE: HRRR requires reorder (y,x)\n",
    "    point_ds = ds.sel(x=yloc, y=xloc)\n",
    "    \n",
    "    return point_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1463a-b3ff-42b9-9618-c7b0985c4c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## NOTE: compare values to previous plots\n",
    "extract_hrrr(ds, points[0]).t2m.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5092f4e2-77ec-456a-8d62-ed62d7f8bb12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extract_hrrr(ds, points[9]).t2m.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fddf84-be87-44fc-919c-b241cff8b7ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract Other Layers\n",
    "\n",
    "Goal is to extract rain, wind, and solar radiation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd92d0c-bcc1-4de5-af25-30c8a774b9ab",
   "metadata": {},
   "source": [
    "#### 10m Vars\n",
    "\n",
    "Wind is in the 10m layer. The core variables are U and V components of wind, and they are combined (via Pythagoras??) into wind speed (m/s).\n",
    "\n",
    "In an ML context, initial weights would be:\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785650a-4d53-4576-98e0-4ff19c9225f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in temp downloaded file from before\n",
    "ds=xr.open_dataset(\n",
    "    tempfile,\n",
    "    filter_by_keys={'typeOfLevel': 'heightAboveGround', 'level': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4fe2d-94a8-437d-ad99-728de43cb7fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x10m = extract_hrrr(ds, points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88db04a-b877-4038-8e74-e268f67c3ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('East Wind: ', x10m.u10.values)\n",
    "print('North Wind: ', x10m.v10.values)\n",
    "print('Wind Speed: ', x10m.si10.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f5d28-c0bf-4e08-b9c3-0f354846d077",
   "metadata": {},
   "source": [
    "#### Surface Vars\n",
    "\n",
    "Extract rain (accumulated and hourly), solar radiation (up/down & long/short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b14d9ee-d7bd-4e95-926d-f1316a8519bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in temp downloaded file from before at 2m level\n",
    "ds=xr.open_dataset(\n",
    "    tempfile,\n",
    "    filter_by_keys={'typeOfLevel': 'surface', 'stepType': 'instant'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99e290-b259-480f-b386-405919151102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs = extract_hrrr(ds, points[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a70d4d-dc33-43ef-b357-0f7b20ddd705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(xs.dswrf.values)\n",
    "print(xs.uswrf.values)\n",
    "print(xs.dlwrf.values)\n",
    "print(xs.dlwrf.values)\n",
    "print(xs.prate.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1dcb51-eaf8-46e3-8c54-42741dbbd623",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d06d1b-5ab0-4235-ab22-827507320294",
   "metadata": {},
   "source": [
    "## Slice Needed Layers\n",
    "\n",
    "Given a HRRR grib file at a particular time, slice off the needed layers and combine into one file. For this project, we get the surface, 2m, and 10m layers using the `xarray` package. This process utilizes a `pandas` dataframe to track which atmospheric variables are needed and which layer they come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea1ee1-4eb6-4341-b4d5-dd2438b547ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vs = pd.DataFrame({\n",
    "    'Common Name': ['temp', 'rh', \n",
    "                    'prate', 'dswrf', 'uswrf', 'dlwrf', 'ulwrf',\n",
    "                    'ewind', 'nwind', 'wind'],\n",
    "    'HRRR Name': ['t2m', 'r2', \n",
    "                  'prate', 'dswrf', 'uswrf', 'dlwrf', 'ulwrf',\n",
    "                  'u10', 'v10', 'si10'],\n",
    "    'Layer': ['2m', '2m', \n",
    "              'surface','surface','surface','surface','surface',\n",
    "              '10m', '10m', '10m']\n",
    "})\n",
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099ed7a-ec79-448b-ad58-b2c3ecbb2386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds1, ds2, ds3 = slice_hrrr(tempfile,vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba9c5fb-8385-486d-aaa7-dcaca16636da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dest_dir = ''\n",
    "time_str = datetime.strptime(str(ds1.time.values),'%Y-%m-%dT%H:%M:%S.%f000').strftime(\"%Y-%m-%d_%H\")\n",
    "os.makedirs(osp.join(dest_dir, time_str), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bdf306-c01d-4007-ba3b-a316e2e5dbf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds1.to_netcdf(osp.join(dest_dir, time_str, time_str +'-hrrr-2m.nc'))\n",
    "ds2.to_netcdf(osp.join(dest_dir, time_str, time_str +'-hrrr-surf.nc'))\n",
    "ds3.to_netcdf(osp.join(dest_dir, time_str, time_str +'-hrrr-10m.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f627d0-d782-4750-8cde-0e24cabb2d6f",
   "metadata": {},
   "source": [
    "## Loop and Slice\n",
    "\n",
    "Given time range (start and stop), loop through the time periods and slice layers, saving in subdirectories. This portion of code will live in the `__main__` portion of the `gather_HRRR` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c98d1-3726-4131-89b3-7a0ab9aa4926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time period of 3 hours in June 2022\n",
    "hrrr_conf = from_json(\"hrrr_conf.json\")\n",
    "\n",
    "# Handle Dates\n",
    "fmt = \"%Y-%m-%d %H:%M\"\n",
    "time1 = datetime.strptime(hrrr_config[\"start_time\"], fmt)\n",
    "time2 = datetime.strptime(hrrr_config[\"end_time\"], fmt)\n",
    "dates = pd.date_range(start=time1,end=time2, freq=\"1H\") # Series of dates in 1 hour increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f744ccb-b880-44e3-a08f-546df7768091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for t in range(0, dates.shape[0]):\n",
    "    # Format time\n",
    "    time=dates[t].strftime(\"%Y-%m-%d %H:%M\")\n",
    "    print('Time '+str(t)+', '+str(time))\n",
    "    \n",
    "    # Format output subdirectory\n",
    "    dest_dir = ''\n",
    "    time_str = datetime.strptime(time,'%Y-%m-%d %H:%M').strftime(\"%Y-%m-%d_%H\")\n",
    "    os.makedirs(osp.join(dest_dir, time_str), exist_ok=True)\n",
    "    \n",
    "    # Temporarily download grib file at given time\n",
    "    tempfile, url = download_grib(\n",
    "        source_url = \"https://noaa-hrrr-bdp-pds.s3.amazonaws.com\",\n",
    "        time = time,\n",
    "        model = \"wrfsfcf\",\n",
    "        dest_dir = osp.join(dest_dir, time_str)\n",
    "    )\n",
    "    \n",
    "    # Slice HRRR grib file\n",
    "    ds1, ds2, ds3 = slice_hrrr(tempfile,vs)\n",
    "    \n",
    "    # Save Slices\n",
    "    ds1.to_netcdf(osp.join(dest_dir, time_str, time_str +'-hrrr-2m.nc'))\n",
    "    ds2.to_netcdf(osp.join(dest_dir, time_str, time_str +'-hrrr-surf.nc'))\n",
    "    ds3.to_netcdf(osp.join(dest_dir, time_str, time_str +'-hrrr-10m.nc'))\n",
    "\n",
    "    os.remove(tempfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c457ac-61bb-4d13-a1fe-a4e21773d6c9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ded1d1-6011-41bc-ab70-0167a2701088",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Code below was found to be quite slow for the application. Future goal is to replace that process using the slices 2d HRRR objects saved above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df73a0-2c54-41d8-acec-48afdc503fa0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Build Timeseries\n",
    "\n",
    "This next step loops through the hours of the time range given at the beginning of the notebook and,\n",
    "\n",
    "* temporarily downloads grib file at that date\n",
    "* extracts values at desired coordinates from temp file to build time series\n",
    "* delete tempfile before iterating\n",
    "\n",
    "Variables extracted with a pandas dataframe specifying layer and variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43c307-ff71-402e-a60a-dbf40cad432a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vs = pd.DataFrame({\n",
    "    'Common Name': ['temp', 'rh', \n",
    "                    'prate', 'dswrf', 'uswrf', 'dlwrf', 'ulwrf',\n",
    "                    'ewind', 'nwind', 'wind'],\n",
    "    'HRRR Name': ['t2m', 'r2', \n",
    "                  'prate', 'dswrf', 'uswrf', 'dlwrf', 'ulwrf',\n",
    "                  'u10', 'v10', 'si10'],\n",
    "    'Layer': ['2m', '2m', \n",
    "              'surface','surface','surface','surface','surface',\n",
    "              '10m', '10m', '10m']\n",
    "})\n",
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ab40b-e94b-4b10-a9d0-e3dac754bb83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hrrr_dat = gather_hrrr_time_range(\n",
    "    start = start_time,\n",
    "    end = end_time,\n",
    "    pts = points,\n",
    "    vs = vs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08c167-0aee-44c9-83dd-1422dea9c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to viz demo above\n",
    "print(hrrr_dat[5,0,0])\n",
    "print(hrrr_dat[5,9,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c459aed-a807-4ad9-a4e9-19a94fb45e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data summary\n",
    "\n",
    "## Simple func to print summary\n",
    "def summary(dat):\n",
    "    ntime = dat.shape[0]\n",
    "    ncoords = dat.shape[1]\n",
    "    nvars = dat.shape[2]\n",
    "    \n",
    "    print('-'*25)\n",
    "    print('Sample Size:')\n",
    "    print('Time: '+str(ntime))\n",
    "    print('Coordinates: '+str(ncoords))\n",
    "    print('Atmospheric Vars: '+str(nvars))\n",
    "    print('-'*25)\n",
    "    \n",
    "summary(hrrr_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af981c6-54ce-4451-af3c-508d76abddd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot a couple time series at a given pt\n",
    "temps2 = hrrr_dat[:,2,0]\n",
    "plt.plot(temps2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb0615-832b-4e52-8212-6524ea4b8e14",
   "metadata": {},
   "source": [
    "## Write Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2a2a5-62c3-41f7-97ec-a94602c53a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hrrr_dict={\n",
    "    'time': pd.date_range(start_time, end_time, freq=\"1H\"),\n",
    "    'coords': points,\n",
    "    'data': hrrr_dat\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efafa34-5882-4a47-b708-823f5e6de01d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('hrrr_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(hrrr_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784344d3-7ec4-4047-82ca-b402018603f6",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "* https://registry.opendata.aws/noaa-hrrr-pds/\n",
    "\n",
    "* https://spire.com/tutorial/spire-weather-tutorial-intro-to-processing-grib2-data-with-python/\n",
    "\n",
    "* https://github.com/microsoft/AIforEarthDataSets/blob/main/data/noaa-hrrr.md\n",
    "\n",
    "* https://nbviewer.org/github/microsoft/AIforEarthDataSets/blob/main/data/noaa-hrrr.ipynb\n",
    "\n",
    "* https://github.com/ecmwf/cfgrib/issues/63\n",
    "\n",
    "* https://github.com/blaylockbk/Herbie/discussions/45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d50875-2cad-40cb-b288-2ced08fc6549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
