{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37200d84-2865-422d-b961-a28da3aa0367",
   "metadata": {},
   "source": [
    "# Data Scaling Tutorial\n",
    "\n",
    "This notebook is meant to introduce some data scaling methods used in machine learning. Scaling features in ML is used for many reasons. Some techniques within ML critically depend on features of on a common scale, such as L1/L2 regularization or nearest-neighbors techniques. In Neural Networks, scaling allows the network to learn the relative contributions of each feature without being dominated by the scale of one feature or another.\n",
    "\n",
    "*Note:* data can be transformed and inverse-transformed using the methods below, but exact results cannot be recovered due to approximation errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0f8a1-ce3c-4931-98b7-6b4c35e9c2aa",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2710ac-2ae8-4e16-bc42-9d4da2c9ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhirs\\anaconda3\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# Local modules\n",
    "sys.path.append('..')\n",
    "import reproducibility\n",
    "from utils import hash2\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from moisture_rnn_pkl import pkl2train\n",
    "from moisture_rnn import create_rnn_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31aae1-b030-455d-8919-3b49d56c9e28",
   "metadata": {},
   "source": [
    "## Setup & Data Read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f00156a-8f3c-4ce1-8c7a-4c1a17dc37d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file='test_CA_202401.pkl'\n",
    "train = pkl2train([file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef48924-6fd5-4c51-8be0-50ec99cc1de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'timesteps': 5,\n",
       " 'optimizer': 'adam',\n",
       " 'rnn_layers': 1,\n",
       " 'rnn_units': 6,\n",
       " 'dense_layers': 1,\n",
       " 'dense_units': 1,\n",
       " 'activation': ['linear', 'linear'],\n",
       " 'centering': [0.0, 0.0],\n",
       " 'dropout': [0.2, 0.2],\n",
       " 'recurrent_dropout': 0.2,\n",
       " 'reset_states': True,\n",
       " 'epochs': 100,\n",
       " 'learning_rate': 0.001,\n",
       " 'phys_initialize': False,\n",
       " 'stateful': True,\n",
       " 'verbose_weights': True,\n",
       " 'verbose_fit': False,\n",
       " 'features_list': ['Ed', 'Ew', 'rain'],\n",
       " 'scale': False,\n",
       " 'scaler': 'minmax',\n",
       " 'train_frac': 0.5,\n",
       " 'val_frac': 0.1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../params.yaml\") as file:\n",
    "    params = yaml.safe_load(file)[\"rnn\"]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f33573-a683-42df-84c4-3def2c71ea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not scaling data\n"
     ]
    }
   ],
   "source": [
    "case = 'KRNC1_202401'\n",
    "rnn_dat = create_rnn_data2(train[case], params)\n",
    "X = rnn_dat[\"X_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "378a92b1-a626-420f-825b-13e7f7d51556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.65665995, 14.24907313,  0.        ],\n",
       "       [16.37073623, 14.95777203,  0.        ],\n",
       "       [16.8830433 , 15.46613268,  0.        ],\n",
       "       [16.58511884, 15.17121406,  0.        ],\n",
       "       [15.42272608, 14.02588457,  0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12737986-1847-42eb-8339-104e2197b4f7",
   "metadata": {},
   "source": [
    "## Min-Max Scaler\n",
    "\n",
    "Rescales data to a given range, (0, 1) by default in `sklearn`. If $x$ is a feature vector, we calculate the transformation $x'$ by:\n",
    "\n",
    "$$\n",
    "x' = \\frac{x-\\min\\{x\\}}{\\max\\{x\\}-\\min\\{x\\}}\n",
    "$$\n",
    "\n",
    "Notice that $x'=0$ if $x$ equals the minimum, and $x'=1$ if $x$ equals the maximum, as desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea996e-2fe3-4b58-8362-655ea73c5c22",
   "metadata": {},
   "source": [
    "### Manual Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d6c3c1-d087-4651-bfc1-9bd4ef161407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X column mins: [9.18025688 7.97581012 0.        ]\n",
      "X column maxs: [34.47706758 32.29556689  1.80660525]\n"
     ]
    }
   ],
   "source": [
    "min = X.min(axis=0)\n",
    "max = X.max(axis=0)\n",
    "print(f\"X column mins: {min}\")\n",
    "print(f\"X column maxs: {max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5141c3ac-cd3d-46ae-992e-97e3f3594d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25601658 0.25794925 0.        ]\n",
      " [0.2842445  0.28709012 0.        ]\n",
      " [0.30449635 0.30799332 0.        ]\n",
      " [0.29271919 0.29586661 0.        ]\n",
      " [0.24676902 0.248772   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "X_scaled = (X - min) / (max - min)\n",
    "\n",
    "print(X_scaled[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11af6579-38f8-4af7-b00e-e90c9e7e6529",
   "metadata": {},
   "source": [
    "The scaled data should have column mins & maxes approximately equal to 0 and 1, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc879733-1fcb-4b09-9357-e2b06fc5c9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-scaled column mins: [0. 0. 0.]\n",
      "X-scaled column maxs: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"X-scaled column mins: {X_scaled.min(axis=0)}\")\n",
    "print(f\"X-scaled column maxs: {X_scaled.max(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb432d-d998-49a6-b9af-ef5627ffca3e",
   "metadata": {},
   "source": [
    "### Using `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e8757c-a0d2-403c-96c9-f0983dc641a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled2 = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654315e5-54b1-4e3c-9028-9e7fd7f70b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25601658 0.25794925 0.        ]\n",
      " [0.2842445  0.28709012 0.        ]\n",
      " [0.30449635 0.30799332 0.        ]\n",
      " [0.29271919 0.29586661 0.        ]\n",
      " [0.24676902 0.248772   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled2[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82a9bb-d5b0-42a5-ba80-7e8f12bcfc21",
   "metadata": {},
   "source": [
    "### Compare Difference\n",
    "\n",
    "The difference between the methods should be approximately zero, or close to machine-epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b28dd98-95be-43c8-8e08-26f05060a8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(X_scaled - X_scaled2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba2f69d-b3c6-4f08-bbe0-4b191970223a",
   "metadata": {},
   "source": [
    "## Standard Scaler\n",
    "\n",
    "Scale features to mean 0 and standard deviation 1, equivalent to z-scores. This method assumes features are approximately normally distributed and will lead to strange results if not. If $x$ is a feature vector of length $N$, we calculate the standard transformation $x'$ by:\n",
    "\n",
    "$$\n",
    "x' = \\frac{x-\\mu}{s}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\\text{Where},\\quad \\mu = \\frac{1}{N}\\sum_{i=1}^n x_i \\quad \\text{And,}\\quad s = \\sqrt{\\sum_{i=1}^n\\frac{(x_i-\\mu)^2}{N}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f43caf-618f-472f-b0d5-dba0db187bea",
   "metadata": {},
   "source": [
    "### Manual Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee69773e-10d5-4da2-8694-95f15dba681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X column means: [17.37172913 15.95227122  0.07087056]\n",
      "X column sds: [4.14878625 4.04256916 0.32151782]\n"
     ]
    }
   ],
   "source": [
    "mu = X.mean(axis=0)\n",
    "s = X.std(axis=0)\n",
    "print(f\"X column means: {mu}\")\n",
    "print(f\"X column sds: {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b9808a6-4d51-4b8d-b1ee-946623edcb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.41339059 -0.42131576 -0.22042497]\n",
      " [-0.24127367 -0.24600672 -0.22042497]\n",
      " [-0.11779007 -0.12025485 -0.22042497]\n",
      " [-0.1896001  -0.19320811 -0.22042497]\n",
      " [-0.46977668 -0.47652534 -0.22042497]]\n"
     ]
    }
   ],
   "source": [
    "X_scaled = (X - mu)/s\n",
    "print(X_scaled[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb5a10e-b7ff-4a12-ba3a-2b52199caef8",
   "metadata": {},
   "source": [
    "The resulting scaled data should have column means approximately equal to zero and column standard deviations approximately equal to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46b90923-692f-4d68-8d2a-29182da17dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-scaled column means: [ 9.78053617e-16 -1.63890066e-16 -1.96271570e-16]\n",
      "X-scaled column sds: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"X-scaled column means: {X_scaled.mean(axis=0)}\")\n",
    "print(f\"X-scaled column sds: {X_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b0a9b-c206-486e-8103-b1a029fde330",
   "metadata": {},
   "source": [
    "### Using `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbab5ddc-dbab-433c-9084-1dc0061b37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled2 = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2fbe910-33e4-4847-86ff-9abf0e661273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.41339059 -0.42131576 -0.22042497]\n",
      " [-0.24127367 -0.24600672 -0.22042497]\n",
      " [-0.11779007 -0.12025485 -0.22042497]\n",
      " [-0.1896001  -0.19320811 -0.22042497]\n",
      " [-0.46977668 -0.47652534 -0.22042497]]\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled2[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5c920-144a-44d4-83b0-e4184cbacb96",
   "metadata": {},
   "source": [
    "### Compare Difference\n",
    "\n",
    "The difference between the methods should be approximately zero, or close to machine-epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaee74cb-d978-4b8e-9fc5-121671afc087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(X_scaled - X_scaled2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62673faf-061c-415d-83b8-f786a87a69ad",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- `MinMaxScaler` from Scikitlearn: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "\n",
    "- `StandardScaler` from Scikitlearn: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985c603-1a97-4e03-88a5-d868dcc38659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
