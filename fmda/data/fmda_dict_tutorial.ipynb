{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c089ba-5037-43e0-82ca-a5f8dcd4c681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhirs\\anaconda3\\lib\\site-packages\\synoptic\\accessors.py:28: UserWarning: map making not available without Brian's cartopy_tools\n",
      "  warnings.warn(\"map making not available without Brian's cartopy_tools\")\n",
      "C:\\Users\\jhirs\\anaconda3\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os\n",
    "import os.path as osp\n",
    "from osgeo import gdal, osr\n",
    "from scipy.interpolate import griddata, RegularGridInterpolator\n",
    "from synoptic.services import stations_timeseries, stations_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3fd0f-d4dc-4d3d-ab91-77bd19e4b64b",
   "metadata": {},
   "source": [
    "# FMDA Dictionary Tutorial\n",
    "\n",
    "The purpose of this notebook is to demonstrate creating fmda dictionaries to be used for training ML models of fuel moisture. This notebook combines the techniques from other notebooks in this directory, so see `interpolation_tutorial` and `synopticpy_tutorial` for more information. This code will live in `wrfxpy` in the python module `build_fmda_dict.py`.\n",
    "\n",
    "**Goals:** given a user input of a date range and latitude/longitude bounding box, return a dictionary with top-level keys for each RAWS station within the bounding box that has fuel moisture data, and then for each station subdictionaries of formatted static location information, RAWS goundlevel sensor data, and atmospheric data from HRRR interpolated to the station location.\n",
    "\n",
    "This notebook will demonstrate retrieving RAWS data using `SynopticPy`, but within `wrfxpy` for older times this data is retrieved from a stash of saved fuel moisture data.\n",
    "\n",
    "*Note:* this requires a formatted stash of geotiff files, which are bands extracted from HRRR grib files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ea125-109c-407a-a9b2-656ceae7604c",
   "metadata": {},
   "source": [
    "## User Inputs\n",
    "\n",
    "Below we manually enter the user inputs to define the spatiotemporal frame for the data collection. Within `wrfxpy`, these arguments are entered from the command line and read within python as system arguments with `sys.argv[...]`. The arguments should be formatted as:\n",
    "\n",
    "* `start`: (str) start time formatted as \"YYYYmmDDHHMM\"\n",
    "* `end`: (str) end time formatted as \"YYYYmmDDHHMM\"\n",
    "* `bbox`: (list) of format `[lonmin, latmin, lonmax, lonmin]` (mimicking format from `SynopticPy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b6f8bb-7cd0-4a36-9c9d-2f26da4c0b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"202401010000\" # Jan 1, 2024, midnight UTC\n",
    "end = \"202401010200\" # Jan 31, 2024, 2am UTC\n",
    "bbox = [-105, 37, -103, 39]\n",
    "\n",
    "# Format times as datetime\n",
    "t0 = datetime.strptime(start, \"%Y%m%d%H%M\")\n",
    "t1 = datetime.strptime(end, \"%Y%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c4812-a346-4501-b34d-a6b8ad4f40bb",
   "metadata": {},
   "source": [
    "## Static Data Objects\n",
    "\n",
    "Below are objects decalred at the start of `build_fmda_dict.py` and used throughout. They include a dataframe of HRRR data bands, determined from [HRRR documentation](https://www.nco.ncep.noaa.gov/pmb/products/hrrr/hrrr.t00z.wrfprsf00.grib2.shtml). Also, there is a file path string object `hrrrpath` which points to the stash of formatted geotiff files. For this tutorial, those data simply live in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4ca7ce6-092f-4a99-931f-626e46f2d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: choosing to exclude solar bands 'DLWRF', 'USWRF', 'ULWRF'\n",
    "# Downward shortwave is expected theoretically to be the most useful solar field \n",
    "# RAWS have downward shortwave sensors, so these could be compared to model fields\n",
    "band_df_hrrr = pd.DataFrame({\n",
    "    'Band': [585, 616, 620, 628, 629, 661],\n",
    "    'hrrr_name': ['GUST', 'TMP', 'RH', 'PRATE', 'APCP',\n",
    "                  'DSWRF'],\n",
    "    'dict_name': [\"wind\", \"temp\", \"rh\", \"rain\", \"precip_accum\",\n",
    "                 \"solarDS\"],\n",
    "    'descr': ['surface Wind Speed (Gust) [m/s]',\n",
    "              '2 m Temperature [K]', \n",
    "              '2 m Relative Humidity [%]', \n",
    "              'surface Precip. Rate [kg/m^2/s]',\n",
    "              'surface Total Precipitation [kg/m^2]',\n",
    "              'surface Downward Short-Wave Radiation Flux [W/m^2]']\n",
    "})\n",
    "\n",
    "hrrrpath = \"geotiff_files\" # path for atmospheric data stash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98974707-72fe-4205-a7b6-593b89e3a8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building FMDA Dictionary for RAWS Sites within [-105, 37, -103, 39]\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "print(f\"Building FMDA Dictionary for RAWS Sites within {bbox}\")\n",
    "print(\"~\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ab6ed9-6a77-447d-913d-e235a429f6f0",
   "metadata": {},
   "source": [
    "## Get RAWS Station Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbc6ca0d-b5a1-4a9a-8997-a86aab96bfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ðŸššðŸ’¨ Speedy Delivery from Synoptic API [metadata]: https://api.synopticdata.com/v2/stations/metadata?bbox=-105,37,-103,39&vars=fuel_moisture&token=ðŸ™ˆHIDDEN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sts = stations_metadata(bbox=bbox,vars=[\"fuel_moisture\"])\n",
    "params = dict(\n",
    "    stid=[\"PLACEHOLDER\"], # change this in the loop\n",
    "    vars=[\"air_temp\", \"relative_humidity\", \"precip_accum\", \"fuel_moisture\", \"wind_speed\", \"solar_radiation\"],\n",
    "    start=t0,\n",
    "    end=t1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651eb955-9768-4841-b0a6-16c5b58ee8ca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def format_precip(precipa):\n",
    "    rain=np.array(precipa, dtype = 'float64')\n",
    "    rain = np.diff(rain) # first difference to convert accumulated to hourly\n",
    "    rain = np.insert(rain, 0, [np.NaN]) # add NaN entry to account for diff\n",
    "    # Highest ever recorded hourly rainfall in inches is about 16: https://www.weather.gov/owp/hdsc_world_record\n",
    "    rain[rain > 100] = np.NaN # filter out erroneously high\n",
    "    rain[rain < 0] = np.NaN # filter out negative, results from diff function after precipa goes to zero\n",
    "    return rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "342d42b9-8c32-408f-b171-931eed01b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_raws_df(df):\n",
    "    # Given input dataframe (the output of retrieve_raws_api), return formatted dictionary\n",
    "    # Inputs:\n",
    "    # df: (dataframe)\n",
    "    # Returns: fmda dictionary\n",
    "\n",
    "    ## Format Return Dictionaries\n",
    "    loc = {\n",
    "        \"STID\": df.attrs[\"STID\"],\n",
    "        'lat' : df.attrs['latitude'],\n",
    "        'lon' : df.attrs['longitude'],\n",
    "        'elev': df.attrs[\"ELEVATION\"]\n",
    "    }\n",
    "    \n",
    "    ## Extract times from dataframe index\n",
    "    times = df.index.strftime('%Y-%m-%dT%H:%M:%SZ').to_numpy() # convert index to utc time\n",
    "    ## Convert dataframe to dictionary\n",
    "    raws = df.to_dict(orient = \"list\")\n",
    "    \n",
    "    # Convert lists to NumPy arrays\n",
    "    raws = {key: np.array(value) for key, value in raws.items()}\n",
    "\n",
    "    raws[\"time_raws\"]=times\n",
    "    raws[\"hours\"]=len(times)\n",
    "    \n",
    "    ## Convert C to K \n",
    "    if df.attrs[\"UNITS\"][\"air_temp\"] == \"Celsius\":\n",
    "        print(\"Converting RAWS temp from C to K\")\n",
    "        raws[\"air_temp\"] = raws[\"air_temp\"]+273.15\n",
    "\n",
    "    ## Calculate Hourly Precipitation from accumulated\n",
    "    if \"precip_accum\" in df.columns:\n",
    "        print(\"Calculating hourly precipitation\")\n",
    "        raws[\"rain\"] = format_precip(raws[\"precip_accum\"])\n",
    "    \n",
    "    return loc, raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e760ab95-217e-4c77-8f32-2f784be544b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to return nested dictionary, \n",
    "# Top-level keys is station ID with start YYYYmm\n",
    "# Next-level keys is location data and RAWS sensor data\n",
    "def build_raws_dict(sts):\n",
    "    # Inputs:\n",
    "    # sts: (df) dataframe of station data, output of stations_metadata\n",
    "    out_dict = {} # set up return dictionary\n",
    "\n",
    "    for st in sts:\n",
    "        print(\"~\"*50)\n",
    "        print(f\"Collecting RAWS data for {st}\")\n",
    "        params[\"stid\"] = [st]\n",
    "        try:\n",
    "            dat = stations_timeseries(verbose=\"HIDE\", **params)\n",
    "    \n",
    "            if \"fuel_moisture\" in dat.columns:\n",
    "                print(\"Collected FMC data\")\n",
    "                loc, raws = format_raws_df(dat)\n",
    "                title = f\"{st}_{t0.year}{t0.strftime('%m')}\"\n",
    "                out_dict[title] = {\"loc\":loc, \"RAWS\": raws}\n",
    "            else:\n",
    "                print(\"No FMC found for this station and time\")\n",
    "        except AssertionError as e:\n",
    "            # Error handling behavior\n",
    "            print(\"AssertionError caught:\", e)\n",
    "            \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b004f467-fed4-4c25-a892-f6573fa7442b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Collecting RAWS data for CCEC2\n",
      "\n",
      " ðŸššðŸ’¨ Speedy Delivery from Synoptic API [timeseries]: https://api.synopticdata.com/v2/stations/timeseries?stid=CCEC2&vars=air_temp,relative_humidity,precip_accum,fuel_moisture,wind_speed,solar_radiation&start=202401010000&end=202401010200&token=ðŸ™ˆHIDDEN\n",
      "\n",
      "Collected FMC data\n",
      "Converting RAWS temp from C to K\n",
      "Calculating hourly precipitation\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Collecting RAWS data for CUHC2\n",
      "\n",
      " ðŸššðŸ’¨ Speedy Delivery from Synoptic API [timeseries]: https://api.synopticdata.com/v2/stations/timeseries?stid=CUHC2&vars=air_temp,relative_humidity,precip_accum,fuel_moisture,wind_speed,solar_radiation&start=202401010000&end=202401010200&token=ðŸ™ˆHIDDEN\n",
      "\n",
      "Collected FMC data\n",
      "Converting RAWS temp from C to K\n",
      "Calculating hourly precipitation\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Collecting RAWS data for CCYC2\n",
      "\n",
      " ðŸššðŸ’¨ Speedy Delivery from Synoptic API [timeseries]: https://api.synopticdata.com/v2/stations/timeseries?stid=CCYC2&vars=air_temp,relative_humidity,precip_accum,fuel_moisture,wind_speed,solar_radiation&start=202401010000&end=202401010200&token=ðŸ™ˆHIDDEN\n",
      "\n",
      "Collected FMC data\n",
      "Converting RAWS temp from C to K\n",
      "Calculating hourly precipitation\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Collecting RAWS data for C2024\n",
      "AssertionError caught: ðŸ›‘ There are errors in the API request https://api.synopticdata.com/v2/stations/timeseries?stid=C2024&vars=air_temp,relative_humidity,precip_accum,fuel_moisture,wind_speed,solar_radiation&start=202401010000&end=202401010200&token=4192c18707b848299783d59a9317c6e1. No stations found for this request, or your account does not have access to the requested station(s). Please contact support@synopticdata.com.\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Collecting RAWS data for PUB5\n",
      "AssertionError caught: ðŸ›‘ There are errors in the API request https://api.synopticdata.com/v2/stations/timeseries?stid=PUB5&vars=air_temp,relative_humidity,precip_accum,fuel_moisture,wind_speed,solar_radiation&start=202401010000&end=202401010200&token=4192c18707b848299783d59a9317c6e1. No stations found for this request, or your account does not have access to the requested station(s). Please contact support@synopticdata.com.\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Collecting RAWS data for CO030\n",
      "\n",
      " ðŸššðŸ’¨ Speedy Delivery from Synoptic API [timeseries]: https://api.synopticdata.com/v2/stations/timeseries?stid=CO030&vars=air_temp,relative_humidity,precip_accum,fuel_moisture,wind_speed,solar_radiation&start=202401010000&end=202401010200&token=ðŸ™ˆHIDDEN\n",
      "\n",
      "No FMC found for this station and time\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Collecting RAWS data for C5608\n",
      "AssertionError caught: ðŸ›‘ There are errors in the API request https://api.synopticdata.com/v2/stations/timeseries?stid=C5608&vars=air_temp,relative_humidity,precip_accum,fuel_moisture,wind_speed,solar_radiation&start=202401010000&end=202401010200&token=4192c18707b848299783d59a9317c6e1. No stations found for this request, or your account does not have access to the requested station(s). Please contact support@synopticdata.com.\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Collecting RAWS data for RDDC2\n",
      "\n",
      " ðŸššðŸ’¨ Speedy Delivery from Synoptic API [timeseries]: https://api.synopticdata.com/v2/stations/timeseries?stid=RDDC2&vars=air_temp,relative_humidity,precip_accum,fuel_moisture,wind_speed,solar_radiation&start=202401010000&end=202401010200&token=ðŸ™ˆHIDDEN\n",
      "\n",
      "No FMC found for this station and time\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Collecting RAWS data for D3809\n",
      "\n",
      " ðŸššðŸ’¨ Speedy Delivery from Synoptic API [timeseries]: https://api.synopticdata.com/v2/stations/timeseries?stid=D3809&vars=air_temp,relative_humidity,precip_accum,fuel_moisture,wind_speed,solar_radiation&start=202401010000&end=202401010200&token=ðŸ™ˆHIDDEN\n",
      "\n",
      "No FMC found for this station and time\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Collecting RAWS data for RRAC2\n",
      "\n",
      " ðŸššðŸ’¨ Speedy Delivery from Synoptic API [timeseries]: https://api.synopticdata.com/v2/stations/timeseries?stid=RRAC2&vars=air_temp,relative_humidity,precip_accum,fuel_moisture,wind_speed,solar_radiation&start=202401010000&end=202401010200&token=ðŸ™ˆHIDDEN\n",
      "\n",
      "Collected FMC data\n",
      "Converting RAWS temp from C to K\n",
      "Calculating hourly precipitation\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Collecting RAWS data for TT568\n",
      "\n",
      " ðŸššðŸ’¨ Speedy Delivery from Synoptic API [timeseries]: https://api.synopticdata.com/v2/stations/timeseries?stid=TT568&vars=air_temp,relative_humidity,precip_accum,fuel_moisture,wind_speed,solar_radiation&start=202401010000&end=202401010200&token=ðŸ™ˆHIDDEN\n",
      "\n",
      "Collected FMC data\n",
      "Converting RAWS temp from C to K\n",
      "Calculating hourly precipitation\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Collecting RAWS data for TT689\n",
      "\n",
      " ðŸššðŸ’¨ Speedy Delivery from Synoptic API [timeseries]: https://api.synopticdata.com/v2/stations/timeseries?stid=TT689&vars=air_temp,relative_humidity,precip_accum,fuel_moisture,wind_speed,solar_radiation&start=202401010000&end=202401010200&token=ðŸ™ˆHIDDEN\n",
      "\n",
      "Collected FMC data\n",
      "Converting RAWS temp from C to K\n",
      "Calculating hourly precipitation\n"
     ]
    }
   ],
   "source": [
    "out_dict = build_raws_dict(sts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bef10c9-54e9-4c3a-86b9-67d7f0aca83f",
   "metadata": {},
   "source": [
    "### View collected data after this step\n",
    "\n",
    "*Note:* this is for illustration only, not done within `wrfxpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8da7433-4737-4fa9-a43f-e1a2cffe5fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CCEC2_202401', 'CUHC2_202401', 'CCYC2_202401', 'RRAC2_202401', 'TT568_202401', 'TT689_202401'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c910c4b-a145-4428-af72-dc87097ae812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc': {'STID': 'CCEC2', 'lat': 37.5425, 'lon': -104.03194, 'elev': 5422},\n",
       " 'RAWS': {'air_temp': array([273.15 , 270.928]),\n",
       "  'fuel_moisture': array([7.4, 7.3]),\n",
       "  'precip_accum': array([0., 0.]),\n",
       "  'relative_humidity': array([64., 81.]),\n",
       "  'solar_radiation': array([14.,  0.]),\n",
       "  'wind_speed': array([2.68, 2.68]),\n",
       "  'time_raws': array(['2024-01-01T00:23:00Z', '2024-01-01T01:23:00Z'], dtype=object),\n",
       "  'hours': 2,\n",
       "  'rain': array([nan,  0.])}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict[[*out_dict.keys()][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9414b2-8976-4e6d-86d1-246fc5d76973",
   "metadata": {},
   "source": [
    "## Get HRRR Data\n",
    "\n",
    "Using dictionary produced by RAWS data retrieval above, fill with time series of interpolated HRRR data at each location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53c863cc-d7f6-46b2-b4fe-18681c70b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projection_info(ds, epsg = 4326):\n",
    "    # Given a geotiff file (a HRRR band), \n",
    "    # return info necessary to transform lat/lon coords to the file structure\n",
    "    # Inputs: \n",
    "    # ds: (osgeo.gdal.Dataset)\n",
    "    # epsg: (int) default 4326 for lon/lat\n",
    "    # Return: (tuple) with fields (ct, g_inv)\n",
    "        # ct: (osgeo.osr.CoordinateTransformation)\n",
    "        # gt_inv: (tuple) output of gdal.InvGeoTransform, also could be found with gdalinfo on command line\n",
    "    gt = ds.GetGeoTransform()\n",
    "    gp = ds.GetProjection()\n",
    "    if(ds.RasterCount>1):\n",
    "        print('Not Implemented for multiple Raster bands')\n",
    "        sys.exit(-1)\n",
    "    # Get Projection info\n",
    "    point_srs = osr.SpatialReference()\n",
    "    point_srs.ImportFromEPSG(4326) # hardcode for lon/lat\n",
    "    # GDAL>=3: make sure it's x/y\n",
    "    # see https://trac.osgeo.org/gdal/wiki/rfc73_proj6_wkt2_srsbarn\n",
    "    point_srs.SetAxisMappingStrategy(osr.OAMS_TRADITIONAL_GIS_ORDER)\n",
    "    file_srs = osr.SpatialReference()\n",
    "    file_srs.ImportFromWkt(gp)\n",
    "    ct = osr.CoordinateTransformation(point_srs, file_srs)\n",
    "    gt_inv = gdal.InvGeoTransform(gt)\n",
    "\n",
    "    return ct, gt_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e88b1c8-3355-4902-b066-f38a10e9f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hrrr_path(d, band):\n",
    "    # Inputs: \n",
    "    # d: (datetime)\n",
    "    # band: (int) HRRR band number\n",
    "    # Returns: (str) filepath to geotiff file\n",
    "    day_file = d.strftime(\"%Y%m%d\") # HRRR data stash is in this format\n",
    "    hour = d.strftime(\"%H\")\n",
    "    tpath = osp.join(hrrrpath, day_file, f\"hrrr.t{hour}z.wrfprsf00.{band}.tif\")\n",
    "    return tpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec6dc2e1-9470-4978-8395-13f4860ab20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hrrr_dict(tstart, tend, dat):\n",
    "    # tstart: (datetime)    start time\n",
    "    # tend: (datetime)     end time\n",
    "    # dat: (dict) dictionary, output of build_raws_dict\n",
    "    \n",
    "    # Get dates array\n",
    "    dates = pd.date_range(start=tstart,end=tend, freq=\"1H\")\n",
    "\n",
    "    # Get Projection data from first band from band_df_hrrr,\n",
    "    # reuse projection info for other bands\n",
    "    # NOTE: this results in 1 extra read of geotiff files, but doing it for clarity\n",
    "    d = dates[0]\n",
    "    band = band_df_hrrr.Band[0]\n",
    "    tpath = build_hrrr_path(d, band)\n",
    "    print(f\"Opening: {tpath}\")\n",
    "    if not osp.exists(tpath): \n",
    "        raise FileNotFoundError(f\"The file '{tpath}' does not exist.\")\n",
    "    ds = gdal.Open(tpath)\n",
    "    ct, gt_inv = get_projection_info(ds)\n",
    "    ds = None # close connection\n",
    "\n",
    "    # Loop over bands, build time series for each station in dictionary\n",
    "    for index, row in band_df_hrrr.iterrows():\n",
    "        print(\"~\"*50)\n",
    "        band = row[\"Band\"]\n",
    "        print(f\"Building Time Series for band: {band}, {row['descr']}\")\n",
    "        for i in range(0, len(dates)):\n",
    "            d = dates[i]\n",
    "            tpath = build_hrrr_path(d, band)\n",
    "            print(f\"Opening: {tpath}\")\n",
    "            ds = gdal.Open(tpath)\n",
    "            \n",
    "            ds = None # close connection\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "137f71b2-27c1-4cc4-a3b1-1ddd9eafda4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Opening: geotiff_files\\20240101\\hrrr.t00z.wrfprsf00.585.tif\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Building Time Series for band: 585, surface Wind Speed (Gust) [m/s]\n",
      "Opening: geotiff_files\\20240101\\hrrr.t00z.wrfprsf00.585.tif\n",
      "Opening: geotiff_files\\20240101\\hrrr.t01z.wrfprsf00.585.tif\n",
      "Opening: geotiff_files\\20240101\\hrrr.t02z.wrfprsf00.585.tif\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Building Time Series for band: 616, 2 m Temperature [K]\n",
      "Opening: geotiff_files\\20240101\\hrrr.t00z.wrfprsf00.616.tif\n",
      "Opening: geotiff_files\\20240101\\hrrr.t01z.wrfprsf00.616.tif\n",
      "Opening: geotiff_files\\20240101\\hrrr.t02z.wrfprsf00.616.tif\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Building Time Series for band: 620, 2 m Relative Humidity [%]\n",
      "Opening: geotiff_files\\20240101\\hrrr.t00z.wrfprsf00.620.tif\n",
      "Opening: geotiff_files\\20240101\\hrrr.t01z.wrfprsf00.620.tif\n",
      "Opening: geotiff_files\\20240101\\hrrr.t02z.wrfprsf00.620.tif\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Building Time Series for band: 628, surface Precip. Rate [kg/m^2/s]\n",
      "Opening: geotiff_files\\20240101\\hrrr.t00z.wrfprsf00.628.tif\n",
      "Opening: geotiff_files\\20240101\\hrrr.t01z.wrfprsf00.628.tif\n",
      "Opening: geotiff_files\\20240101\\hrrr.t02z.wrfprsf00.628.tif\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Building Time Series for band: 629, surface Total Precipitation [kg/m^2]\n",
      "Opening: geotiff_files\\20240101\\hrrr.t00z.wrfprsf00.629.tif\n",
      "Opening: geotiff_files\\20240101\\hrrr.t01z.wrfprsf00.629.tif\n",
      "Opening: geotiff_files\\20240101\\hrrr.t02z.wrfprsf00.629.tif\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Building Time Series for band: 661, surface Downward Short-Wave Radiation Flux [W/m^2]\n",
      "Opening: geotiff_files\\20240101\\hrrr.t00z.wrfprsf00.661.tif\n",
      "Opening: geotiff_files\\20240101\\hrrr.t01z.wrfprsf00.661.tif\n",
      "Opening: geotiff_files\\20240101\\hrrr.t02z.wrfprsf00.661.tif\n"
     ]
    }
   ],
   "source": [
    "print(\"~\"*50)\n",
    "build_hrrr_dict(t0, t1, out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5da39-eb1a-4632-9331-374b7fda33ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
